> Una revisión sistemática de la literatura sobre sistemas de recomendación educativa para la enseñanza y el aprendizaje: tendencias de investigación, limitaciones y oportunidades.

Resumen
Los sistemas de recomendación se han convertido en una de las herramientas principales para el filtrado de contenido personalizado en el ámbito educativo. Aquellos que apoyan las actividades de enseñanza y aprendizaje, en particular, han ganado atención creciente en los últimos años. Este creciente interés ha motivado la emergencia de nuevos enfoques y modelos en el campo; sin embargo, existe una brecha en la literatura sobre las tendencias actuales en cómo se han producido las recomendaciones, cómo se han evaluado los recomendadores, así como cuáles son las limitaciones y oportunidades de investigación para avanzar en el campo. En este sentido, este artículo presenta los principales hallazgos de una revisión sistemática de la literatura que abarca estas cuatro dimensiones. El estudio se basa en el análisis de un conjunto de estudios primarios (N = 16 de 756, publicados entre 2015 y 2020) incluidos según criterios definidos. Los resultados indican que el enfoque híbrido ha sido la estrategia principal para la producción de recomendaciones. En cuanto al propósito de la evaluación, los recomendadores fueron evaluados principalmente en términos de precisión, y se encontró un número reducido de estudios que investigaron su efectividad pedagógica. Esta evidencia señala una oportunidad de investigación potencial para el desarrollo de marcos de evaluación multidimensionales que apoyen eficazmente la verificación del impacto de las recomendaciones en el proceso de enseñanza y aprendizaje. Además, identificamos y discutimos las principales limitaciones para aclarar las dificultades actuales que requieren atención en futuras investigaciones.

1. Introducción
Las tecnologías digitales se integran cada vez más en diferentes ámbitos de aplicación. Particularmente en la educación, existe un gran interés en utilizarlas como mediadoras del proceso de enseñanza y aprendizaje. En esta tarea, los dispositivos computacionales sirven como instrumentos para apoyar la adquisición de conocimientos humanos desde diferentes metodologías educativas y prácticas pedagógicas (Becker, 1993).

En este sentido, los Sistemas de Recomendación Educativa (ERS, por sus siglas en inglés) desempeñan un papel importante tanto para educadores como para estudiantes (Maria et al., 2019). Para los instructores, estos sistemas pueden contribuir a sus prácticas pedagógicas a través de recomendaciones que mejoren su planificación y ayuden en el filtrado de recursos educativos. En cuanto a los alumnos, mediante el reconocimiento de preferencias y restricciones educativas, los recomendadores pueden contribuir a su rendimiento académico y motivación al indicar contenido de aprendizaje personalizado (Garcia-Martinez & Hamou-Lhadj, 2013).

A pesar de los beneficios, existen problemas conocidos en el uso de los sistemas de recomendación en el ámbito educativo. Uno de los principales desafíos es encontrar una correspondencia adecuada entre las expectativas de los usuarios y las recomendaciones (Cazella et al., 2014). Las dificultades surgen de las diferencias en los intereses y necesidades educativas de los estudiantes (Verbert et al., 2012). La variedad de factores individuales de los estudiantes que pueden influir en el proceso de aprendizaje (Buder & Schwind, 2012) es uno de los asuntos desafiantes que hacen que sea complejo superarlos. Desde el punto de vista de los recomendadores, esto refleja una diversidad de entradas con potencial para ajustar las recomendaciones para los usuarios.

Desde otra perspectiva, desde un punto de vista tecnológico e de inteligencia artificial, es probable que los ERS sufran problemas ya conocidos en los "field complicated for wannonce also th J know ?" 

Dado que el tema de los Sistemas de Recomendación Educativa (ERS) ha aumentado gradualmente su atracción para la comunidad científica (Zhong et al., 2019), se han llevado a cabo extensas investigaciones en los últimos años para abordar estos problemas (Manouselis et al., 2010; Manouselis et al., 2014; Tarus et al., 2018; George & Lal, 2019). Los ERS se han convertido en un campo de aplicación y combinación de diferentes técnicas computacionales, como la minería de datos, el filtrado de información y el aprendizaje automático, entre otras (Tarus et al., 2018). Este escenario indica una diversidad en el diseño y evaluación de sistemas de recomendación que apoyan actividades de enseñanza y aprendizaje. Sin embargo, la investigación está dispersa en la literatura y no hay estudios recientes que abarquen los esfuerzos científicos actuales en el campo y que revelen cómo se abordan estos problemas en la investigación actual. Revisar la evidencia y sintetizar los hallazgos de los enfoques actuales en cómo los ERS producen recomendaciones, cómo se evalúan y cuáles son las limitaciones y oportunidades de investigación puede proporcionar una perspectiva panorámica sobre el tema de investigación y apoyar a los profesionales e investigadores en la implementación y direcciones futuras de investigación.

Desde la perspectiva mencionada anteriormente, este trabajo tiene como objetivo investigar y resumir las principales tendencias y oportunidades de investigación sobre el tema de los ERS a través de una Revisión Sistemática de la Literatura (SLR, por sus siglas en inglés). El estudio se realizó basado en las publicaciones de los últimos seis años, en particular, en relación con los recomendadores que apoyan el proceso de enseñanza y aprendizaje.

Las principales tendencias se refieren a la dirección reciente de la investigación en el campo de los ERS. Se analizan en cuanto a cómo los sistemas de recomendación producen recomendaciones y cómo se evalúan. Como se mencionó anteriormente, estas son dimensiones significativas relacionadas con los problemas actuales del área. Específicamente para la producción de recomendaciones, este artículo proporciona un análisis basado en tres ejes centrados en las técnicas subyacentes de los sistemas, los datos de entrada y la presentación de resultados.

Además, se destacan las oportunidades de investigación en el campo de los ERS, así como sus principales limitaciones. Debido a que la comprensión actual de estos aspectos está fragmentada en la literatura, dicho análisis puede arrojar luz sobre futuros estudios.

La SLR se llevó a cabo siguiendo las pautas de Kitchenham y Charters (2007). La SLR es el método principal para resumir evidencia relacionada con un tema o una pregunta de investigación (Kitchenham et al., 2009). A su vez, las pautas de Kitchenham y Charters (2007) son una de las principales orientaciones para revisiones sobre tecnología de la información en educación (Dermeval et al., 2020).

El resto de este documento está estructurado de la siguiente manera. En la Sección 2 se presentan los trabajos relacionados. La Sección 3 detalla la metodología utilizada para llevar a cabo la SLR. La Sección 4 cubre los resultados de la SLR y la discusión relacionada. La Sección 5 presenta la conclusión.

2. Trabajos relacionados
En el campo de la educación, hay un creciente interés en las tecnologías que apoyan las actividades de enseñanza y aprendizaje. Con este propósito, los Sistemas de Recomendación Educativa (ERS) son soluciones estratégicas para proporcionar una experiencia educativa personalizada. La investigación en este sentido ha atraído la atención de la comunidad científica y ha habido un esfuerzo por mapear y resumir diferentes aspectos del campo en los últimos 6 años.

Drachsler et al. (2015) llevaron a cabo una revisión exhaustiva de los sistemas de recomendación mejorados por tecnología para el aprendizaje. Los autores analizaron 82 artículos publicados desde 2000 hasta 2014 y proporcionaron una visión general del área. Se analizaron diferentes aspectos sobre el enfoque de los recomendadores, la fuente de información y la evaluación. Además, se presentó un marco de categorización y el estudio incluyó la clasificación de los artículos seleccionados según este marco.

Klašnja-Milićević et al. (2015) realizaron una revisión sobre sistemas de recomendación para entornos de e-learning. El estudio se centra en los requisitos, desafíos, ventajas y desventajas de las técnicas en el diseño de este tipo de ERS. También se discute un análisis sobre sistemas de etiquetado colaborativo y su integración en los recomendadores de plataformas de e-learning.

Ferreira et al. (2017) investigaron las particularidades de la investigación sobre ERS en Brasil. Se analizaron artículos publicados entre 2012 y 2016 en tres vehículos científicos brasileños. Rivera et al. (2018) presentaron una visión general del área de los ERS a través de un mapeo sistemático. El estudio cubrió un conjunto más amplio de artículos y tuvo como objetivo detectar características globales en la investigación sobre ERS. Con el mismo enfoque, pero estableciendo preguntas diferentes y combinaciones de repositorios, Pinho, Barwaldt, Espíndola, Torres, Pias, Topin, Borba y Oliveira (2019) realizaron una revisión sistemática sobre ERS. En estos trabajos, se observa la preocupación común por proporcionar ideas sobre los métodos de evaluación de los sistemas y las principales técnicas adoptadas en el proceso de recomendación.

Nascimento et al. (2017) llevaron a cabo una SLR que cubrió sistemas de recomendación de objetos de aprendizaje basados en los estilos de aprendizaje del usuario. Se investigaron estándares de metadatos de objetos de aprendizaje, modelos teóricos de estilos de aprendizaje, sistemas de e-learning utilizados para proporcionar recomendaciones y las técnicas utilizadas por los ERS.

Tarus et al. (2018) y George y Lal (2019) centraron sus revisiones en los ERS basados en ontologías. Tarus et al. (2018) examinaron la distribución de la investigación en un período de 2005 a 2014 según sus años de publicación. Además, los autores resumieron las técnicas, la representación del conocimiento, los tipos de ontologías y las representaciones de ontologías cubiertas en los artículos. George y Lal (2019), por su parte, actualizan las contribuciones de Tarus et al. (2018), investigando artículos publicados entre 2010 y 2019. Los autores también discuten cómo los ERS basados en ontologías pueden utilizarse para abordar problemas tradicionales de los sistemas de recomendación, como el problema de inicio en frío y la escasez de calificaciones.

Ashraf et al. (2021) dirigieron su atención a investigar sistemas de recomendación de cursos. A través de una revisión exhaustiva, el estudio resumió las técnicas y parámetros utilizados por este tipo de ERS. Además, se definió una taxonomía de los factores considerados en el proceso de recomendación de cursos. Salazar et al. (2021), por otro lado, llevaron a cabo una revisión sobre ERS basados en afectividad. Los autores presentaron un análisis macro, identificando a los principales autores y tendencias de investigación, y resumieron diferentes aspectos de los sistemas de recomendación, como las técnicas utilizadas en el análisis de la afectividad, la fuente de recopilación de datos de afectividad y cómo modelar las emociones.

Khanal et al. (2019) revisaron sistemas de recomendación de e-learning basados en algoritmos de aprendizaje automático. Se examinaron un total de 10 artículos de dos vehículos científicos y publicados entre 2016 y 2018. El punto focal del estudio fue investigar cuatro categorías de recomendadores: aquellos basados en filtrado colaborativo, filtrado basado en contenido, conocimiento y una estrategia híbrida. Las dimensiones analizadas fueron los algoritmos de aprendizaje automático utilizados, el proceso de evaluación de los recomendadores, la caracterización de entradas y salidas y los desafíos abordados por los recomendadores.

2.1 Brechas en los trabajos relacionados y contribución de este estudio

Los estudios presentados en la sección anterior tienen una diversidad de alcances y dimensiones de análisis, sin embargo, en general, pueden clasificarse en dos grupos distintos. El primero se enfoca en temas específicos del campo de los ERS, como métodos similares de recomendaciones (George & Lal, 2019; Khanal et al., 2019; Salazar et al., 2021; Tarus et al., 2018) y tipos similares de recursos recomendables (Ashraf et al., 2021; Nascimento et al., 2017). Este tipo de investigación examina las particularidades de los recomendadores y destaca aspectos que son difíciles de identificar en revisiones con un alcance más amplio. A pesar de esto, la mayoría de las revisiones se concentran en el análisis de las características operativas de los recomendadores y tienen una discusión limitada sobre cuestiones transversales, como la evaluación y los enfoques de presentación de los ERS. Khanal et al. (2019), específicamente, realiza contribuciones en cuanto a la evaluación, pero el análisis se limita a cuatro tipos de sistemas de recomendación.

El segundo grupo está compuesto por revisiones de alcance más amplio e incluye modelos de recomendación basados en una diversidad de métodos, estrategias de entradas y salidas (Drachsler et al., 2015; Ferreira et al., 2017; Klašnja-Milićević et al., 2015; Pinho et al., 2019; Rivera et al., 2018). Debido a la naturaleza de los mapeos sistemáticos, la investigación realizada por Ferreira et al. (2017) y Rivera et al. (2018) no profundiza en algunos temas, por ejemplo, los datos sintetizados sobre las evaluaciones de los ERS se limitan a indicar solo los métodos utilizados. Ferreira et al. (2017), en particular, tiene como objetivo investigar solo sistemas de recomendación brasileños, ofreciendo contribuciones parciales para comprender el estado del arte del área. En Pinho et al. (2019) se observa la misma limitación de los mapeos sistemáticos. La revisión se informó con un número limitado de páginas, lo que dificulta detallar los hallazgos. Por otro lado, Drachsler et al. (2015) y Klašnja-Milićević et al. (2015) llevaron a cabo revisiones exhaustivas que resumen dimensiones específicas y macro del área. Sin embargo, los artículos incluidos en sus revisiones fueron publicados hasta 2014 y hay un vacío en cuanto a los avances y tendencias en el campo en los últimos 6 años.

Dado lo anterior, hasta donde los autores tienen conocimiento, no existe un estudio secundario de alcance amplio que agregue los logros de investigación en sistemas de recomendación que apoyan la enseñanza y el aprendizaje en los últimos años. Además, una revisión en este sentido es necesaria dado que la personalización se ha convertido en una característica importante en el contexto de la enseñanza y el aprendizaje, y los ERS son una de las principales herramientas para abordar diferentes necesidades educativas y preferencias que afectan el proceso de aprendizaje de los individuos.

Con el fin de ampliar las fronteras del conocimiento en el campo de la investigación, esta revisión tiene como objetivo contribuir al área mediante la presentación de un análisis detallado de las siguientes dimensiones: cómo se producen y presentan las recomendaciones, cómo se evalúan los sistemas de recomendación y cuáles son las limitaciones y oportunidades de investigación. Específicamente, para resumir el conocimiento actual, se realizó una SLR basada en cuatro preguntas de investigación (Sección 3.1). La revisión se centró en artículos publicados de 2015 a 2020 en revistas científicas. Se realizó una evaluación de calidad para seleccionar los sistemas más maduros. Los datos encontrados sobre los temas investigados se resumen y discuten en la Sección 4.

3 Metodología

Este estudio se basa en la metodología de Revisión Sistemática de la Literatura (SLR) para recopilar evidencias relacionadas con el tema de investigación investigado. Según Kitchenham y Charters (2007) y Kitchenham et al. (2009), este método proporciona los medios para agregar evidencias de la investigación actual, priorizando la imparcialidad y la reproducibilidad de la revisión. Por lo tanto, una SLR se basa en un proceso que implica el desarrollo de un protocolo de revisión que guía la selección de estudios relevantes y la posterior extracción de datos para su análisis.

Las directrices para la SLR están ampliamente descritas en la literatura y el método se puede aplicar para recopilar evidencias en diferentes dominios, como medicina y ciencias sociales (Khan et al., 2003; Pai et al., 2004; Petticrew & Roberts, 2006; Moher et al., 2015). Específicamente para el área de informática en educación, las directrices de Kitchenham y Charters (2007) han sido reportadas como una de las principales orientaciones (Dermeval et al., 2020). Su enfoque aparece en varios estudios (Petri & Gresse von Wangenheim, 2017; Medeiros et al., 2019; Herpich et al., 2019), incluidos mapeos y revisiones en el campo de los ERS (Rivera et al., 2018; Tarus et al., 2018).

Como se mencionó en la Sección 1, las directrices de Kitchenham y Charters (2007) fueron utilizadas en la SLR realizada. Estas se basan en tres etapas principales: la primera para planificar la revisión, la segunda para llevarla a cabo y la última para el informe de resultados. Siguiendo estas orientaciones, la revisión se estructuró en tres fases con siete actividades principales distribuidas entre ellas, como se muestra en la Figura 1.

La primera fase fue la fase de planificación. La identificación de la necesidad de una SLR sobre recomendadores de apoyo a la enseñanza y el aprendizaje, y el desarrollo del protocolo de revisión ocurrieron en esta etapa. En la actividad 1, se realizó la búsqueda de SLR con el alcance previsto para este estudio. El resultado no devolvió documentos compatibles con el alcance de esta revisión. Los documentos identificados se describen en la Sección 2. En la actividad 2, se definió el proceso de revisión. El protocolo se elaboró mediante rondas de discusión entre los autores hasta alcanzar un consenso. El resultado de la actividad 2 fueron las preguntas de investigación, la estrategia de búsqueda, la estrategia de selección de documentos y el método de extracción de datos.

La siguiente fase fue la fase de ejecución. En este punto, se ejecutaron actividades para la identificación (actividad 3) y selección (actividades 4) de documentos relevantes. En la Actividad 3, se realizaron búsquedas en siete repositorios indicados por Dermeval et al. (2020) como relevantes para el área de informática en educación. Los autores aplicaron la cadena de búsqueda en los motores de búsqueda de estos repositorios, sin embargo, debido al gran número de investigaciones devueltas, los autores establecieron el límite de 600 a 800 documentos que se analizarían. Por lo tanto, se eligieron tres repositorios cuya suma de resultados de búsqueda estuvo dentro de los límites establecidos. La lista de repositorios potenciales considerados para esta revisión y los seleccionados se enumeran en la Sección 3.1. La cadena de búsqueda utilizada también se muestra en la Sección 3.1.

En la actividad 4, los estudios se seleccionaron mediante dos pasos. En el primero, se aplicaron criterios de inclusión y exclusión a cada documento identificado. Los documentos aceptados fueron evaluados en cuanto a su calidad en el segundo paso. Parsifal1 se utilizó para gestionar los datos de la fase de planificación y ejecución. Parsifal es un sistema web que, siguiendo las directrices de Kitchenham y Charters (2007), ayuda en la realización de SLR. Al final de este paso, se extrajeron los datos relevantes (actividad 5) y se registraron en una hoja de cálculo. Finalmente, en la fase de informe, los datos extraídos se analizaron para responder a las preguntas de investigación de la SLR (actividad 6) y los resultados se registraron en este documento (actividad 7).

Figura 1 Fases y actividades de la revisión sistemática de la literatura.

3.1 Preguntas de investigación, cadena de búsqueda y repositorios

Los sistemas recomendadores de apoyo a la enseñanza y el aprendizaje tienen particularidades en cuanto a configuración, diseño y método de evaluación. Por lo tanto, se elaboraron las siguientes preguntas de investigación (Tabla 1) en un esfuerzo por sintetizar estos conocimientos, así como las principales limitaciones y oportunidades de investigación en el campo desde la perspectiva de los estudios más recientes:

En cuanto a la estrategia de búsqueda, los documentos se seleccionaron de tres repositorios digitales (Tabla 2). Para la búsqueda, "Educación" y "Sistema recomendador" se definieron como palabras clave y se derivaron sinónimos de ellas como términos secundarios (Tabla 3). A partir de estas palabras, se elaboró la siguiente cadena de búsqueda:

("Education" OR "Educational" OR "E-learning" OR "Learning" OR "Learn") AND ("Recommender system" OR "Recommender systems" OR "Recommendation system" OR "Recommendation systems" OR "Recommending system" OR "Recommending systems")

3.2 Criterios de inclusión y exclusión

El primer paso para la selección de los documentos se llevó a cabo mediante la aplicación de criterios objetivos, por lo tanto, se definieron un conjunto de criterios de inclusión y exclusión. Los documentos aprobados formaron un grupo que comprende los estudios primarios con relevancia potencial para el alcance del SLR. En la Tabla 4 se enumeran los criterios definidos. En la columna de descripción de la Tabla 4, se informan los criterios y en la columna "id" se identifican con un código. Este último se definió agregando una abreviatura del tipo respectivo de criterio (IC para Criterios de Inclusión y EC para Criterios de Exclusión) con un índice siguiendo la secuencia de la lista. El "id" se utiliza para hacer referencia a su criterio correspondiente en el resto de este documento.

Dado que el enfoque de esta revisión se centra en el análisis de publicaciones recientes de ERS, solo se examinaron estudios de los últimos 6 años (2015-2020) (ver IC1). Para apuntar a sistemas recomendadores maduros, solo se consideraron artículos completos de revistas científicas que presentaran la evaluación del sistema de recomendaciones (ver IC2, IC4 e IC7). Además, solo se seleccionaron trabajos escritos en inglés, debido a que son los más numerosos y están dentro de la capacidad de lectura de los autores (ver IC3). La cadena de búsqueda se verificó en el título, resumen y palabras clave de los documentos para garantizar que solo se examinaran estudios relacionados con el campo de los ERS (ver IC5). El IC6, específicamente, delimitó el tema de los artículos seleccionados y lo alineó con el alcance de la revisión. Además, evitó la selección de estudios secundarios en proceso (por ejemplo, otras revisiones o mapeos sistemáticos).

Por el contrario, se definieron criterios de exclusión para aclarar que los documentos que no cumplieran con los criterios de inclusión debían ser excluidos de la revisión (ver EC1 a EC8). Finalmente, las búsquedas duplicadas fueron marcadas y, cuando se cumplían todos los criterios, solo se seleccionaba la versión más reciente.

Id Pregunta de investigación Razonamiento
RQ1 ¿Cómo producen recomendaciones los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje?
Existe una variedad de parámetros de entrada y técnicas utilizadas para construir sistemas de recomendación para la enseñanza y el aprendizaje (Drachsler et al., 2015; Manouselis et al., 2014). Se han propuesto en un intento de encontrar el mejor enfoque para ajustar las expectativas de los usuarios y las recomendaciones. Además, incluyen por diseño las limitaciones intrínsecas de cada estrategia (Garcia-Martinez & Hamou-Lhadj, 2013). Actualmente, los estudios están dispersos en la literatura y, según los autores, no hay investigaciones que sintetizen el conocimiento sobre las técnicas y entradas utilizadas para abordar los problemas del campo. Analizar las tendencias de los últimos 6 años debería aclarar el estado actual del arte sobre cómo se ha diseñado este tipo de recomendador y las últimas tendencias en este sentido.

RQ2 ¿Cómo presentan los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje las recomendaciones?
Complementariamente a RQ1, esta pregunta de investigación conduce a un análisis amplio de la arquitectura de los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje propuestos por la comunidad científica. Esta pregunta de investigación se suma a RQ1 y amplía las perspectivas del estado del arte actual sobre cómo se han diseñado los ERS.

RQ3 ¿Cómo se evalúan los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje?
Existen distintos métodos que buscan medir las dimensiones de calidad de un recomendador educativo y un estudio previo ha sugerido una creciente conciencia de la necesidad de la elaboración de evaluaciones enfocadas en la educación en el campo de la investigación de los ERS (Erdt et al., 2015). Analizar las tendencias de los últimos 6 años sobre la evaluación de los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje arrojará luz sobre el estado actual del arte y revelará conocimientos sobre qué objetivos de evaluación se han priorizado, así como cómo se ha medido la efectividad pedagógica de los recomendadores.

RQ4 ¿Cuáles son las limitaciones y oportunidades de investigación relacionadas con el campo de los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje?
A medida que el área de investigación de los ERS ha desarrollado en los últimos años, se han reportado o pueden observarse en los estudios actuales las limitaciones de la investigación que obstaculizan los avances en el campo. Además, una investigación en profundidad puede informar sobre temas poco explorados que necesitan más investigación, teniendo en cuenta su potencial para contribuir al avance del área. En la medida en que los autores son conscientes, la literatura carece de la identificación de las limitaciones y oportunidades actuales en la investigación de los sistemas de recomendación de apoyo a la enseñanza y el aprendizaje. Con esta pregunta de investigación se pretende revelarlas desde la perspectiva de la producción científica de los últimos 6 años. Responder a esta pregunta puede aclarar las necesidades de investigación futura en este tema.

3.3 Evaluación de calidad
El segundo paso en la actividad de selección de estudios fue la evaluación de la calidad de los artículos. Se definieron una serie de preguntas con respuestas de diferentes pesos para estimar la calidad de los estudios. El objetivo de esta fase fue filtrar investigaciones con mayor: (i) validez; (ii) detalles del contexto e implicaciones de la investigación; y (iii) descripción de los recomendadores propuestos. Los estudios que detallaron la configuración del experimento y realizaron una validación externa del ERS obtuvieron un peso más alto en la evaluación de calidad. Por lo tanto, las preguntas relacionadas con la evaluación del recomendador (QA8 y QA9) oscilaron de 0 a 3, mientras que las demás, de 0 a 2. Las preguntas y sus respectivas respuestas se presentan en la Tabla 7 (ver Apéndice). Cada artículo evaluado tuvo un peso total calculado según la Fórmula 1:

El peso total de los artículos varió de 0 a 10. Solo se aceptaron trabajos que alcanzaron el peso mínimo de 7.

3.4 Proceso de selección
El proceso de selección de los artículos se llevó a cabo como se muestra en la Figura 2. Inicialmente, tres autores realizaron la identificación de los estudios. En esta actividad, se aplicó la cadena de búsqueda en los motores de búsqueda de los repositorios junto con los criterios de inclusión y exclusión a través de configuraciones de filtrado. Se realizaron dos búsquedas en los tres repositorios en momentos distintos, una en noviembre de 2020 y otra en enero de 2021. La segunda se llevó a cabo para asegurar que todos los artículos publicados en 2020 en los repositorios fueran contabilizados. Se devolvieron un total de 756 estudios primarios preliminares y sus metadatos se registraron en Parsifal.

Siguiendo el protocolo, se inició la actividad de selección. Al principio, se utilizó la función de verificación de duplicidad de Parsifal. Se identificaron un total de 5 artículos duplicados y se ignoraron las copias más antiguas. Posteriormente, los artículos se dividieron en grupos y se distribuyeron entre los autores. Los criterios de inclusión y exclusión se aplicaron mediante la lectura de títulos y resúmenes. En los casos en los que no fue posible determinar la elegibilidad de los artículos basándose en estos dos campos, se leyó el cuerpo del texto hasta que fue posible aplicar todos los criterios con precisión. Finalmente, quedaron 41 estudios para el siguiente paso. Una vez más, los artículos se dividieron en tres grupos y cada conjunto de trabajos fue evaluado por un autor. Los estudios se leyeron en su totalidad y se ponderaron según cada pregunta de evaluación de calidad. En cualquier etapa de este proceso, cuando surgieron preguntas, los autores definieron una solución a través de consenso. Como resultado final de la actividad de selección, se aprobaron 16 artículos para la extracción de datos.

3.5 Procedimiento para el análisis de datos
Los datos de los artículos seleccionados se extrajeron en un formulario de recopilación de datos que registraba información general e información específica. La información general extraída incluía: identificación del revisor, fecha de extracción de datos, título, autores y origen del artículo. Esta información general se utilizó para gestionar la actividad de extracción de datos. La información específica consistió en: enfoque de recomendación, técnicas de recomendación, parámetros de entrada, estrategia de recopilación de datos, método para la recopilación de datos, metodología de evaluación, configuración de evaluación, enfoques de evaluación y métricas de evaluación. Esta información se utilizó para responder a las preguntas de investigación. Los registros tabulados fueron interpretados y se preparó un resumen descriptivo con los hallazgos obtenidos.

4. Resultados y discusión

En esta sección se presentan los resultados de la revisión sistemática de la literatura (SLR, por sus siglas en inglés). Primero, se introduce una visión general de los artículos seleccionados. A continuación, se analizan los hallazgos desde la perspectiva de cada pregunta de investigación en una subsección respectiva.

4.1 Visión general de los artículos seleccionados

Cada artículo seleccionado presenta un enfoque de recomendación distinto que avanza en el campo de los sistemas de recomendación para el apoyo en la enseñanza y el aprendizaje. A continuación, se proporciona una visión general de estos estudios:

Sergis y Sampson (2016) presentan un sistema de recomendación que apoya las prácticas de enseñanza de los educadores a través de la selección de objetos de aprendizaje de repositorios educativos. Genera recomendaciones basadas en el nivel de competencias en TIC de los instructores.

En Tarus et al. (2017), las recomendaciones están dirigidas a los estudiantes. El estudio propone un recomendador de recursos de e-learning basado tanto en la información del usuario como en la del ítem, mapeadas a través de ontologías.

Nafea et al. (2019) proponen tres enfoques de recomendación. Combinan las calificaciones de los ítems con los estilos de aprendizaje de los estudiantes para la recomendación de objetos de aprendizaje.

Klašnja-Milićević et al. (2018) presentan un recomendador de materiales de aprendizaje basado en etiquetas definidas por los estudiantes. El recomendador está incorporado en el sistema de e-learning Protus.

Fig. 2 Flujo de búsqueda y selección de artículos

En Wan y Niu (2016), se propone un sistema de recomendación basado en mapas conceptuales mixtos y algoritmos inmunológicos. Este sistema produce secuencias de objetos de aprendizaje para estudiantes. En un enfoque diferente, los mismos autores incorporan la teoría de autoorganización en los sistemas de recomendación para el aprendizaje (ERS, por sus siglas en inglés). Wan y Niu (2018) tratan la noción de objetos de aprendizaje autoorganizados. En esta investigación, los recursos se comportan como individuos que pueden moverse hacia los estudiantes. Este movimiento resulta en recomendaciones y se desencadena según los atributos de aprendizaje y acciones de los estudiantes. Wan y Niu (2020), a su vez, la autoorganización se refiere al enfoque de los estudiantes motivados por sus necesidades de aprendizaje. Los autores proponen un ERS que recomienda grupos autoorganizados de estudiantes y, basándose en estos, recomienda objetos de aprendizaje.

Zapata et al. (2015) desarrollaron una estrategia de recomendación de objetos de aprendizaje para profesores. El estudio describe una metodología basada en estrategias de colaboración y agregación de votos para las recomendaciones grupales. Este enfoque se implementa en el sistema de recomendación Delphos. En una línea de investigación similar, Rahman y Abdullah (2018) muestran un ERS que recomienda resultados de Google adaptados al perfil académico de los estudiantes. El sistema propuesto clasifica a los estudiantes en grupos y, según la similitud de sus miembros, indica páginas web relacionadas con intereses compartidos.

Wu et al. (2015) proponen un sistema de recomendación para entornos de e-learning. En este estudio, la complejidad y las incertidumbres relacionadas con los datos de perfil de usuario y las actividades de aprendizaje se modelan a través de estructuras de árbol combinadas con lógica difusa. Las recomendaciones se producen a partir de coincidencias de estas estructuras. Ismail et al. (2019) desarrollaron un recomendador para apoyar el aprendizaje informal. Sugiere contenido de Wikipedia teniendo en cuenta datos textuales no estructurados de la plataforma y el comportamiento del usuario.

Huang et al. (2019) presentan un sistema para recomendar cursos opcionales. Las indicaciones del sistema se basan en las limitaciones de tiempo del plan de estudios del estudiante y en la similitud del rendimiento académico entre él y los estudiantes mayores. El tiempo que las personas dedican al aprendizaje también es un factor relevante en Nabizadeh et al. (2020). En esta investigación, se propone un recomendador de trayectorias de aprendizaje que incluye lecciones y objetos de aprendizaje. Este sistema estima el puntaje de buen rendimiento del aprendiz y, basándose en eso, produce una trayectoria de aprendizaje que satisfaga sus limitaciones de tiempo. El enfoque de recomendación también proporciona indicación de recursos auxiliares para aquellos que no alcanzan el rendimiento estimado.

Fernandez-Garcia et al. (2020) abordan las recomendaciones de disciplinas a través de un conjunto de datos con pocas instancias y dispersos. Los autores desarrollaron un modelo basado en varias técnicas de minería de datos y aprendizaje automático para apoyar la decisión de los estudiantes al elegir materias. Wu et al. (2020) crean un recomendador que captura el dominio de un tema por parte de los estudiantes y produce una lista de ejercicios con un nivel de dificultad adaptado a ellos. Yanes et al. (2020) desarrollaron un sistema de recomendación, basado en diferentes algoritmos de aprendizaje automático, que proporciona acciones apropiadas para ayudar a los profesores a mejorar la calidad de las estrategias de enseñanza.

4.2  Cómo los sistemas de recomendación para el soporte del aprendizaje y la enseñanza producen recomendaciones
El proceso de generación de recomendaciones se analiza basándose en dos ejes. En primer lugar, se discuten las técnicas subyacentes de los sistemas de recomendación y luego se cubren los parámetros de entrada. Los detalles de los estudios se proporcionan en la Tabla 5.

4.2.1  Enfoques técnicos
A través del análisis de los artículos seleccionados se observa que los sistemas de recomendación híbridos son predominantes. Estos sistemas se caracterizan por calcular predicciones a través de dos o más algoritmos para mitigar o evitar las limitaciones de los sistemas de recomendación pura (Isinkaye et al., 2015). De los dieciséis artículos analizados, trece (81,25%) se basan en la hibridación. Esta tendencia parece estar relacionada con el soporte que el enfoque híbrido proporciona para el desarrollo de sistemas de recomendación que deben cumplir múltiples necesidades educativas de los usuarios. Por ejemplo, Sergis y Sampson (2016) propusieron un sistema de recomendación basado en dos técnicas principales: conjuntos difusos para manejar la incertidumbre sobre el nivel de competencia del maestro y Filtrado Colaborativo (CF) para seleccionar objetos de aprendizaje basados en vecinos que pueden tener similitudes de competencias. En Tarus et al. (2017), los perfiles de estudiantes y recursos de aprendizaje se representan como ontologías. El sistema calcula predicciones basadas en ellos y recomienda elementos de aprendizaje a través de un mecanismo que aplica filtrado colaborativo seguido de un algoritmo de minería de patrones secuenciales.

Además, el enfoque híbrido que combina CF y Filtrado Basado en Contenido (CBF), aunque es una técnica tradicional (Bobadilla, Ortega, Hernando y Gutiérrez, 2013), no parece ser popular en la investigación de sistemas de recomendación para el soporte del aprendizaje y la enseñanza. De los artículos seleccionados, solo Nafea et al. (2019) tiene una propuesta en este sentido. Además, los datos extraídos indican que un número significativo de sistemas de recomendación híbridos (53,85%, n = 7) se han construido basándose en la combinación de métodos de tratamiento o representación de datos, como el uso de ontologías y conjuntos difusos, con métodos para generar recomendaciones. Por ejemplo, Wu et al. (2015) estructuran los datos del perfil del usuario y las actividades de aprendizaje a través de árboles difusos. En tales estructuras, los valores asignados a sus nodos están representados por conjuntos difusos. El modelo de datos del árbol difuso y las calificaciones de los usuarios alimentan un método de coincidencia de datos estructurados en forma de árbol y un algoritmo de CF para el cálculo de similitudes.

El paradigma de recomendación colaborativa (CF), a su vez, juega un papel importante en la investigación. Casi un tercio de los estudios (30,77%, n = 4) que proponen sistemas de recomendación híbridos incluyen una estrategia basada en CF. De hecho, esta es la técnica pura más frecuente en el conjunto de investigación. Un total del 31,25% (n = 5) se basa en una versión adaptada de CF o lo combina con otros enfoques. En contraste, los recomendadores basados en CBF no han compartido la misma popularidad. Esta técnica es un enfoque establecido de recomendación que produce resultados basados en la similitud entre los elementos conocidos por el usuario y otros elementos recomendables (Bobadilla et al., 2013). Solo Nafea et al. (2019) propone un sistema de recomendación basado en CBF.

Además, la variante basada en usuarios de CF se utiliza ampliamente en la investigación analizada. En esta versión, las predicciones se calculan por similitud entre usuarios, a diferencia de la versión basada en ítems donde las predicciones se basan en similitudes de ítems (Isinkaye et al., 2015). Todos los sistemas de recomendación basados en CF identificados, ya sean puros o combinados con otras técnicas, utilizan esta variante.

Estos hallazgos parecen estar relacionados con la creciente percepción, en el ámbito educativo, de la relevancia de un proceso de enseñanza y aprendizaje centrado en el estudiante (Krahenbuhl, 2016; Mccombs, 2013). Los enfoques de recomendación que se basan en el perfil de los usuarios, como intereses, necesidades y capacidades, se ajustan naturalmente a esta noción y se utilizan más ampliamente que aquellos basados en otra información, como las características de los elementos recomendados.

4.2.2 Enfoques de los parámetros de entrada
Con respecto a los datos utilizados en el proceso de recomendación, los datos recopilados muestran que los principales parámetros son atributos relacionados con el perfil educativo de los usuarios. Ejemplos son las competencias en TIC (Sergis & Sampson, 2016); objetivos de aprendizaje (Wan & Niu, 2018; Wu et al., 2015), estilos de aprendizaje (Nafea et al., 2019), niveles de aprendizaje (Tarus et al., 2017) y diferentes datos académicos (Yanes et al., 2020; Fernández-García et al., 2020). Solo el 25% (n = 4) de los sistemas aplican información relacionada con los elementos en el proceso de recomendación. Además, con la excepción de la recomendación basada en CBF de Nafea et al. (2019), los otros se basan en una combinación de información de elementos e información de usuarios. Una lista completa de los parámetros de entrada identificados se proporciona en la Tabla 5.

La información académica y los estilos de aprendizaje, en comparación con otros parámetros, destacan notablemente en la investigación. Aparecen, respectivamente, en el 37.5% (n = 6) y el 31.25% (n = 5) de los artículos. Las calificaciones de los estudiantes (Huang et al., 2019), antecedentes académicos (Yanes et al., 2020), categorías de aprendizaje (Wu et al., 2015) y materias cursadas (Fernández-García et al., 2020) son algunos de los datos académicos utilizados. Los estilos de aprendizaje, a su vez, se basan predominantemente en la teoría de Felder (1988). Wan y Niu (2016), excepcionalmente, combinan Felder (1988), Kolb et al. (2001) y Betoret (2007) para construir una noción específica de estilos de aprendizaje. Esto también se utiliza en otros dos estudios realizados por los mismos autores y tiene un cuestionario desarrollado por ellos (Wan & Niu, 2018, 2020).

En cuanto a la forma en que se capturan los datos de entrada, se observó que se prioriza el feedback explícito sobre otras estrategias de recopilación de datos. En este enfoque, los usuarios deben proporcionar directamente la información que se utilizará en el proceso de preparación de recomendaciones (Isinkaye et al., 2015). La mitad de los estudios analizados se basan únicamente en feedback explícito. El uso de componentes de interfaz gráfica (Klašnja-Milićević et al., 2018), cuestionarios (Wan & Niu, 2016) e introducción manual de conjuntos de datos (Wu et al., 2020; Yanes et al., 2020) son los principales métodos identificados.

Solo el 18.75% (n = 3) de los sistemas ERS se basan únicamente en la recopilación de información a través de feedback implícito, es decir, cuando los datos de entrada son inferidos por el sistema (Isinkaye et al., 2015). Este tipo de recopilación de datos parece ser más popular cuando se aplica junto con un método de feedback explícito para mejorar las tareas de predicción. Los recomendadores que combinan ambos enfoques ocurren en el 31.25% (n = 5) de los estudios. Los métodos de recopilación de datos implícitos identificados son el seguimiento de datos de usuarios, como el historial de acceso, navegación y calificación (Rahman & Abdullah, 2018; Sergis & Sampson, 2016; Wan & Niu, 2018), extracción de datos de otro sistema (Ismail et al., 2019), monitoreo de sesiones de datos de usuarios (Rahman & Abdullah, 2018) y estimación de datos (Nabizadeh et al., 2020).

Los resultados mencionados indican que, en el contexto de los sistemas de recomendación para el soporte del aprendizaje y la enseñanza, la recolección implícita de datos generalmente se ha explorado de manera complementaria a la explícita. Una posible razón es que la inferencia de información es ruidosa y menos precisa (Isinkaye et al., 2015) y, por lo tanto, las recomendaciones producidas a partir de ella implican una mayor complejidad para ajustarse a las expectativas de los usuarios (Nichols, 1998). Este aspecto dificulta aplicar la estrategia de manera aislada y puede ser un factor que genere mayor insatisfacción del usuario en comparación con la carga de adquisición desventajosa de los inputs de la estrategia explícita.

4.3 Cómo presentan los sistemas de recomendación para el soporte del aprendizaje y la enseñanza las recomendaciones

De los documentos analizados, se identifican dos enfoques para presentar recomendaciones. La mayoría de los ERS propuestos se basan en una lista de elementos clasificados según un cálculo de predicción por usuario (p = 87.5%, n = 14). Esta estrategia se aplica en todos los casos donde la tarea es encontrar buenos elementos que asistan a los usuarios en tareas de enseñanza y aprendizaje (Ricci et al., 2015; Drachsler et al., 2015). El segundo enfoque se basa en la generación de trayectorias de aprendizaje. En este caso, las recomendaciones se muestran a través de una serie de elementos vinculados por algunos prerrequisitos. Solo 2 sistemas de recomendación utilizan este enfoque. En ellos, la secuencia se establece mediante atributos de asociación de objetos de aprendizaje (Wan & Niu, 2016) y mediante una combinación de conocimientos previos del usuario, el tiempo disponible y un puntaje de aprendizaje (Nabizadeh et al., 2020). Estos ERS están asociados con la tarea de recomendación de secuencias de elementos y están destinados a guiar a los usuarios que desean alcanzar un conocimiento específico (Drachsler et al., 2015).

En un análisis más detenido, se observa que más de la mitad (62.5%, n = 10) no presenta detalles sobre cómo se presenta la lista de recomendaciones al usuario final. En Huang et al. (2019), por ejemplo, hay una descripción vaga de la producción de puntajes predichos para los estudiantes y una lista de los cursos opcionales principales y no se especifica cómo se muestra esta lista. Esto puede estar relacionado con el hecho de que la mayoría de estos sistemas de recomendación no informan sobre una integración en otro sistema (por ejemplo, sistemas de gestión del aprendizaje) o el propósito de hacerlo disponible como una herramienta independiente (por ejemplo, sistema de recomendación web o móvil). La ausencia de tales requisitos mitiga la necesidad de desarrollar una interfaz de presentación refinada. Solo Tarus et al. (2017), Wan y Niu (2018) y Nafea et al. (2019) proponen sistemas de recomendación incorporados en un sistema de e-learning y no detallan la forma en que se exhiben los resultados. En los seis artículos que proporcionan información sobre la presentación de recomendaciones, algunos de ellos (33.33%, n = 2) tienen una interfaz gráfica que busca captar la atención del usuario que puede estar realizando otra tarea en el sistema. Este enfoque destaca las recomendaciones y es común en sistemas comerciales (Beel, Langer y Genzmehr, 2013). En Rahman and Abdullah (2018), se utiliza un panel titulado "recomendaciones para ti". En Ismail et al. (2019), se muestra una ventana emergente con sugerencias para el usuario. La otra parte de los estudios muestra recomendaciones orgánicas, es decir, elementos dispuestos naturalmente para la interacción del usuario (Beel et al., 2013).

En Zapata et al. (2015), después de que el usuario define algunos parámetros, se devuelve una lista de objetos de aprendizaje recomendados de manera similar a un resultado de motor de búsqueda. En cuanto a los métodos de agregación, otro elemento recomendado por el sistema, solo se recomienda la estrategia que mejor se adapte a los intereses del grupo. El resultado se visualiza a través de una escala Likert de cinco estrellas que representa la calificación de consenso de los usuarios. En Klašnja-Milićević et al. (2018) y Wu et al. (2015), los resultados de los recomendadores se enumeran en el área principal del sistema. En Nabizadeh et al. (2020), el camino de aprendizaje ocupa un panel en la pantalla y los elementos asociados se muestran a medida que el usuario avanza en los pasos. La vista de los objetos de aprendizaje auxiliares no se describe en el artículo. Estos tres últimos sistemas de recomendación no incluyen ajustes de filtrado y se alejan del arquetipo de un motor de búsqueda.

Además, un número significativo de investigaciones se centra en recomendaciones de objetos de aprendizaje (p = 56.25%, n = 9). Otros elementos recomendables identificados son actividades de aprendizaje (Wu et al., 2015), acciones pedagógicas (Yanes et al., 2020), páginas web (Ismail et al., 2019; Rahman & Abdullah, 2018), ejercicios (Wu et al., 2020), métodos de agregación (Zapata et al., 2015), lecciones (Nabizadeh et al., 2020) y asignaturas (Fernández-García et al., 2020). Ningún estudio relaciona la forma de mostrar los resultados con el artículo recomendado. Este es un tema que requiere una investigación adicional para responder si existen formas más apropiadas de presentar tipos específicos de elementos al usuario.

4.4 Cómo se evalúan los sistemas de recomendación para el soporte del aprendizaje y la enseñanza

En los ERS, existen tres metodologías principales de evaluación (Manouselis et al., 2013). Una de ellas es el experimento offline, que se basa en el uso de datos pre-recopilados o simulados para probar la calidad de predicción de los recomendadores (Shani & Gunawardana, 2010). El estudio de usuario es el segundo enfoque. Se lleva a cabo en un entorno controlado donde se recopilan datos relacionados con las interacciones reales de los usuarios (Shani & Gunawardana, 2010). Este tipo de evaluación puede realizarse, por ejemplo, mediante cuestionarios y pruebas A/B (Shani & Gunawardana, 2010). Finalmente, el experimento online, también conocido como prueba en condiciones reales, es aquel en el que los recomendadores se utilizan en condiciones reales por parte de los usuarios previstos (Shani & Gunawardana, 2010).

A la luz de estas definiciones, las investigaciones analizadas comprenden solo estudios de usuario y experimentos offline en los experimentos reportados. Cada uno de estos métodos se identificó en el 68.75% (n = 11) de los artículos respectivamente. Es importante señalar que no son exclusivos para todos los casos, por lo que la suma de los porcentajes es mayor al 100%. Por ejemplo, Klašnja-Milićević et al. (2018) y Nafea et al. (2019) evaluaron la calidad de las predicciones de ERS a partir del análisis de conjuntos de datos y también pidieron a los usuarios que usaran los sistemas para investigar su atractivo. Ambos métodos de evaluación se llevan a cabo conjuntamente en el 37.5% (n = 6) de los artículos. Cuando se comparan con el uso exclusivo de métodos, cada uno se lleva a cabo en el 31.25% (n = 5). Por lo tanto, parece que los dos métodos tienen una popularidad equilibrada. Los tests en condiciones reales, por el contrario, aunque son los que mejor demuestran la calidad de un recomendador (Shani & Gunawardana, 2010), son los más evitados, probablemente debido al alto costo y complejidad de ejecución.

Un hallazgo interesante concierne a los métodos de estudio de usuario utilizados en la investigación. Cuando se asocian con experimentos offline, la evaluación de la satisfacción del usuario es la más común (p = 80%, n = 5). De estos, solo Nabizadeh et al. (2020) realizó una evaluación profunda combinando un cuestionario de satisfacción con un experimento para verificar la efectividad pedagógica de su recomendador. Wu et al. (2015), en particular, no incluye una encuesta de satisfacción. Realizaron una investigación cualitativa de las interacciones y experiencias de los usuarios.

Aunque los cuestionarios ayudan a identificar información valiosa de los usuarios, son sensibles a las intenciones de los encuestados y pueden estar sesgados con respuestas erróneas (Shani & Gunawardana, 2010). Los artículos que presentan solo estudios de usuario, en contraste, tienen una tasa más alta de experimentos que proporcionan evidencia directa sobre la efectividad del recomendador en la enseñanza y el aprendizaje. Todos los artículos en este grupo tienen alguna investigación en este sentido. Wan y Niu (2018), por ejemplo, verificaron si el recomendador influyó en la calificación académica de los estudiantes y en el tiempo para alcanzar un objetivo de aprendizaje. Rahman y Abdullah (2018) investigaron si el recomendador afectó el tiempo que los estudiantes tardaron en completar una tarea.

En cuanto al propósito de las evaluaciones, se identificaron diez objetivos de investigación distintos. A través de la Figura 3, se observa que la investigación de precisión sobresale sobre los demás. Solo 1 estudio no realizó experimentos en este sentido. Se identificaron diferentes métricas tradicionales para medir la precisión de los recomendadores. El Error Absoluto Medio (MAE), en particular, tiene la frecuencia más alta. La Tabla 6 enumera las principales métricas identificadas.

El análisis de la atractividad del sistema, mediante la verificación de la satisfacción del usuario, tiene la segunda mayor ocurrencia. Está presente en el 62.5% (n = 10) de los estudios. La evaluación de la efectividad pedagógica de los ERS tiene una participación reducida en los estudios y ocurre solo en el 37.5% (n = 6). También se identificaron experimentos para examinar la diversidad de recomendaciones, la precisión en la obtención del perfil del usuario, el proceso de evolución, la experiencia e interacciones del usuario, la entropía, la novedad y la utilidad y facilidad percibida, aunque en menor medida.

Además, el 81.25% (n = 13) de los artículos presentaron experimentos para lograr múltiples propósitos. Por ejemplo, en Wan y Niu (2020) se lleva a cabo una evaluación para investigar la efectividad pedagógica de los recomendadores, la satisfacción de los estudiantes, la precisión, la diversidad de recomendaciones y la entropía. Solo en Huang et al. (2019), Fernández-García et al. (2020) y Yanes et al. (2020) se evaluó una sola dimensión del sistema de recomendación.

Los resultados sugieren un compromiso de la comunidad científica en demostrar la calidad de los sistemas de recomendación desarrollados a través de un análisis multidimensional. Sin embargo, los experimentos offline y los estudios de usuario, particularmente aquellos basados en cuestionarios, son los más adoptados y pueden llevar a interpretaciones incompletas o sesgadas. Por lo tanto, estos datos también señalan la necesidad de un mayor esfuerzo para realizar pruebas y experimentos en condiciones reales que conduzcan a una comprensión del impacto real de los recomendadores en el proceso de enseñanza y aprendizaje. Las investigaciones que sinteticen y discutan las posibilidades empíricas de evaluar la efectividad pedagógica de los ERS pueden ayudar a aumentar la popularidad de estos experimentos.

A través del análisis de los artículos también se encuentra que los resultados de los experimentos offline suelen basarse en una mayor cantidad de datos en comparación con los estudios de usuario. En este grupo, el 63.64% (n = 7) de los conjuntos de datos de evaluación tienen registros de más de 100 usuarios. Los estudios de usuario, por otro lado, predominan en conjuntos de hasta 100 participantes en los experimentos (72.72%, n = 8). En general, las evaluaciones offline que tienen conjuntos de datos más pequeños son aquellas que se realizan en asociación con un estudio de usuario. Esto se debe a que los datos para ambos experimentos generalmente provienen de los mismos sujetos (Nafea et al., 2019; Tarus et al., 2017). El costo (por ejemplo, tiempo y dinero) relacionado con el estudio de los participantes para el experimento es posiblemente un factor determinante en la definición de muestras adecuadas.

Además, también se verifica que la mayor parte de los experimentos offline tiene un enfoque de división del 70/30% para los datos de entrenamiento y prueba. Nguyen et al. (2021) ofrecen algunas ideas en este sentido argumentando que esta es la proporción más adecuada para entrenar y validar modelos de aprendizaje automático. Se presentan más detalles sobre los enfoques y métricas de evaluación de sistemas de recomendación en la Tabla 6.

4.5 Limitaciones y oportunidades de investigación relacionadas con el campo de los sistemas de recomendación para el soporte del aprendizaje y la enseñanza

Las principales limitaciones observadas en los artículos seleccionados se presentan a continuación. Estas se basan en declaraciones explícitas de los artículos y en formulaciones de los autores. En esta sección, solo se enumeran aquellas que son transversales a la mayoría de los estudios. A continuación, se señalan una serie de oportunidades de investigación para investigaciones futuras.

4.5.1 Limitaciones de la investigación
Las limitaciones de investigación son factores que obstaculizan el progreso actual en el campo de los ERS. Conocer estos factores puede ayudar a los investigadores a intentar enfrentarlos en sus estudios y mitigar la posibilidad de estancamiento del área, es decir, cuando los nuevos recomendadores propuestos no generan realmente mejores resultados que los baselines (Anelli et al., 2021; Dacrema et al., 2021). Como resultado de esta revisión sistemática, se identificaron limitaciones de investigación en tres áreas que se presentan a continuación.

Restricción de reproducibilidad: La mayoría de los artículos informan sobre conjuntos de datos específicamente recopilados para evaluar los ERS propuestos. La principal razón de esto es la escasez de conjuntos de datos públicos adecuados para las necesidades de investigación, como destacan algunos autores (Nabizadeh et al., 2020; Tarus et al., 2017; Wan & Niu, 2018; Wu et al., 2015; Yanes et al., 2020). Este enfoque restringe la viabilidad de la reproducción del experimento y dificulta la comparación entre recomendadores. De hecho, este es un problema antiguo en el campo de los ERS. Verbert et al. (2011) observaron, a principios de la última década, la necesidad de mejorar la reproducibilidad y la comparación en los ERS para proporcionar conclusiones más sólidas sobre su validez y generalizabilidad. Aunque hubo un esfuerzo en esta dirección en los años siguientes basado en el intercambio amplio de conjuntos de datos educativos, actualmente la mayoría de los conocidos (Çano & Morisio, 2015; Drachsler et al., 2015) han sido retirados, y los restantes demostraron no ser suficientes para satisfacer las demandas actuales de investigación. De los estudios analizados, solo Wu et al. (2020) utilizan conjuntos de datos educativos públicos.

Dado que el intercambio de conjuntos de datos juega un papel importante en la reproducción y comparación de modelos de recomendadores en las mismas condiciones, este hallazgo resalta la necesidad de un esfuerzo por parte de la comunidad investigadora para la creación de medios que satisfagan esta necesidad (por ejemplo, el desarrollo de repositorios públicos) con el fin de mitigar la limitación actual de reproducibilidad.

Tamaño del conjunto de datos / Número de sujetos: Como se puede observar en la Tabla 6, unos pocos resultados experimentales se basan en una gran cantidad de datos. Solo cinco estudios tienen información de 1000 o más usuarios. En particular, la evaluación offline realizada por Wu et al. (2015), a pesar de tener un conjunto de datos extenso, utiliza registros de MovieLens y no se basa en información real relacionada con la enseñanza y el aprendizaje. Otra limitación se refiere a la procedencia de los datos, que generalmente provienen de un solo origen (por ejemplo, una clase universitaria).

Aunque los experimentos basados en conjuntos de datos pequeños pueden revelar la relevancia de un ERS, una evaluación basada en un conjunto de datos a gran escala debería proporcionar conclusiones más sólidas sobre la efectividad de la recomendación (Verbert et al., 2011). Los experimentos basados en datos más grandes y diversos (por ejemplo, usuarios de diferentes áreas y dominios) contribuirían a resultados más generalizables. Por otro lado, la escasez de conjuntos de datos públicos puede estar afectando la cantidad y diversidad de datos utilizados en los experimentos científicos en el campo de los ERS. Como informó Nabizadeh et al. (2020), el aumento del tamaño del experimento es costoso en diferentes aspectos. Si hubiera más conjuntos de datos públicos disponibles, es más probable que los investigadores encuentren aquellos que puedan alinearse con sus necesidades y, naturalmente, aumentar el tamaño de su experimento. En este sentido, podrían verse favorecidos al reducir la dificultad y el costo de adquisición de datos. Además, la comunidad científica tendría acceso a datos de usuarios fuera de su contexto circundante y podría basar sus experimentos en datos diversificados.

Falta de investigación en profundidad del impacto de problemas conocidos en el campo de los sistemas de recomendación: El inicio en frío, la sobre-especialización y la dispersión son algunos de los desafíos conocidos en el campo de los sistemas de recomendación (Khusro et al., 2016). Están principalmente relacionados con un número reducido y desigualmente distribuido de retroalimentaciones de usuarios o descripciones de elementos utilizados para generar recomendaciones (Kunaver & Požrl, 2017). Estos problemas también permean el campo de los ERS. Por ejemplo, en Cechinel et al. (2011) se informó que en una muestra de más de 6000 objetos de aprendizaje del repositorio Merlot se observó un número reducido de calificaciones de usuarios sobre los elementos. Cechinel et al. (2013), por su parte, observaron, en un conjunto de datos del mismo repositorio, un patrón de pocos usuarios calificando varios recursos mientras que la gran mayoría califica con 5 o menos. Dado que estos problemas impactan directamente la calidad de las recomendaciones, los recomendadores de soporte para la enseñanza y el aprendizaje deben ser evaluados considerando tales problemas para clarificar en qué medida pueden ser efectivos en situaciones de la vida real. Contrariamente, en esta revisión sistemática, detectamos un número significativo de artículos (43.75%, n = 7) que no analizan o discuten cómo los recomendadores manejan, al menos parcialmente, estos problemas. Los estudios que se basan en experimentos para examinar tales aspectos elucidarían más detalles sobre la calidad de los sistemas propuestos.

4.5.2 Oportunidades de investigación

A partir de los documentos analizados, se identificó un conjunto de oportunidades de investigación. Estas se basan en las lagunas relacionadas con los temas explorados a través de las preguntas de investigación de esta revisión sistemática. Las oportunidades identificadas ofrecen ideas sobre temas poco explorados que necesitan una investigación adicional, teniendo en cuenta su potencial para contribuir al avance del campo de los ERS. Las oportunidades de investigación se identificaron en tres áreas que se presentan a continuación.

Estudio del potencial de los atributos de usuario ignorados: Los documentos examinados presentan ERS basados en una variedad de entradas. Las preferencias, conocimientos previos, estilo de aprendizaje y objetivos de aprendizaje son algunos ejemplos (la Tabla 5 tiene la lista completa). De hecho, como informan Chen y Wang (2021), esto está alineado con una tendencia actual de investigación que investiga las relaciones entre las diferencias individuales y el aprendizaje personalizado. Sin embargo, una evidencia que surge de esta revisión sistemática también confirma que "algunas diferencias individuales esenciales son descuidadas en los trabajos existentes" (Chen & Wang, 2021). La muestra de los documentos sugiere una falta de estudios que incorporen, en el modelo de recomendación, otra información notablemente relevante, como el estado emocional y el contexto cultural de los estudiantes (Maravanyika & Dlodlo, 2018; Salazar et al., 2021; Yanes et al., 2020). Esto indica que se necesita una investigación adicional para aclarar las verdaderas contribuciones y las complejidades existentes para recopilar, medir y aplicar estos otros parámetros. En este sentido, una oportunidad de investigación abierta se refiere a la investigación de estos otros atributos de los usuarios para explorar el impacto de tales características en la calidad de los resultados de los ERS.

Aumento de estudios sobre la aplicación de ERS en situaciones de aprendizaje informal: El aprendizaje informal se refiere a un tipo de aprendizaje que típicamente ocurre fuera de una institución educativa (Pöntinen et al., 2017). En él, los aprendices no siguen un currículo estructurado ni tienen un experto en el dominio que los guíe (Pöntinen et al., 2017; Santos & Ali, 2012). Estos aspectos influyen en cómo los ERS pueden apoyar a los usuarios. Por ejemplo, en entornos informales, el contenido puede provenir de múltiples proveedores, y como consecuencia, puede entregarse sin seguir una secuencia pedagógica adecuada. Los ERS que apuntan a este escenario deberían concentrarse en organizar y secuenciar recomendaciones que guíen el proceso de aprendizaje de los usuarios (Drachsler et al., 2009).

Aunque la literatura destaca la existencia de diferencias significativas en el diseño de recomendadores educativos que involucran circunstancias de aprendizaje formal o informal (Drachsler et al., 2009; Okoye et al., 2012; Manouselis et al., 2013; Harrathi & Braham, 2021), a través de esta revisión sistemática se observó que los estudios actuales tienden a no ser explícitos al informar esta característica. Este escenario dificulta obtener un panorama claro de la situación actual del campo en esta dimensión. No obstante, a través de las características de los ERS propuestos, se observó que la investigación actual parece estar concentrada en el contexto de aprendizaje formal. Esto se debe a que los recomendadores de los documentos analizados generalmente utilizan datos mantenidos por sistemas de aprendizaje institucionales. Además, las recomendaciones, predominantemente, no proporcionan una secuencia pedagógica para apoyar el aprendizaje autodirigido y a su propio ritmo (por ejemplo, recomendaciones que construyen un camino de aprendizaje para alcanzar conocimientos específicos). Por el contrario, el aprendizaje informal ha ganado cada vez más atención de la comunidad científica con la aparición de la pandemia de coronavirus (Watkins & Marsick, 2020).

A la luz de esto, la falta de estudios de ERS dirigidos a entornos de aprendizaje informal abre una oportunidad de investigación. Específicamente, una investigación adicional centrada en el diseño y la evaluación de recomendadores que tengan en cuenta diferentes contextos (por ejemplo, ubicación o dispositivo utilizado) y que guíen a los usuarios a través de una secuencia de aprendizaje para lograr un conocimiento específico tendría un lugar destacado en este contexto, considerando el formato menos estructurado que tienen las circunstancias de aprendizaje informal en términos de objetivos de aprendizaje y apoyo al aprendizaje.

Estudios sobre el desarrollo de marcos de evaluación multidimensionales: La evidencia de este estudio muestra que el propósito principal de la evaluación de ERS ha sido evaluar la precisión de los recomendadores y la satisfacción de los usuarios (Sección 4.4). Este resultado, conectado con Erdt et al. (2015), revela dos décadas de evaluación predominantemente basadas en estos dos objetivos. Aunque otros propósitos de evaluación han tenido una participación reducida en la investigación, también son críticos para medir el éxito de los ERS. Moubayed et al. (2018), por ejemplo, destaca dos aspectos de evaluación de sistemas de e-learning, uno se refiere a cómo evaluar adecuadamente el rendimiento del estudiante, y el otro se refiere a medir los avances en el aprendizaje de los estudiantes a través del uso de sistemas. Tahereh et al. (2013) identifica que las partes interesadas y los indicadores asociados con la calidad tecnológica son relevantes para considerar en la evaluación de sistemas educativos. Desde la perspectiva del campo de los sistemas de recomendación, también hay aspectos importantes que analizar en el contexto de su aplicación en el dominio educativo, como la novedad y la diversidad (Pu et al., 2011; Cremonesi et al., 2013; Erdt et al., 2015).

En este contexto, se observa que, aunque evaluar la precisión de los recomendadores y la satisfacción de los usuarios proporciona información sobre el valor de los ERS, no son suficientes para indicar completamente la calidad del sistema en el apoyo al proceso de aprendizaje. Otros factores diferentes reportados en la literatura son relevantes para tener en cuenta. Sin embargo, hasta donde llega nuestro conocimiento, no existe un marco que identifique y organice estos factores a considerar en la evaluación de un ERS, lo que dificulta que la comunidad científica esté al tanto de ellos e incorpore estos aspectos en los estudios.

Dado que la evaluación de los ERS necesita ser un esfuerzo conjunto entre científicos de la computación y expertos de otros campos (Erdt et al., 2015), se deben realizar investigaciones adicionales buscando el desarrollo de un marco de evaluación multidimensional que abarque los requisitos de evaluación desde una perspectiva multidisciplinaria. Estudios de este tipo clarificarían las diferentes dimensiones que tienen el potencial de contribuir a una mejor evaluación de los ERS y podrían incluso identificar cuál debería priorizarse para evaluar verdaderamente el impacto del aprendizaje con un costo reducido.

5 Conclusiones

En los últimos años, ha habido un esfuerzo científico extenso para desarrollar recomendadores que satisfagan diversas necesidades educativas; sin embargo, la investigación está dispersa en la literatura y no hay un estudio reciente que englobe los esfuerzos científicos actuales en el campo.

Dado este contexto, este artículo presenta una Revisión Sistemática de la Literatura (SLR, por sus siglas en inglés) que tiene como objetivo analizar y sintetizar las principales tendencias, limitaciones y oportunidades de investigación relacionadas con los sistemas de recomendación para el apoyo al enseñanza y aprendizaje. Específicamente, este estudio contribuye al campo proporcionando un resumen y un análisis de la información disponible actualmente sobre el tema de los sistemas de recomendación para el apoyo al enseñanza y aprendizaje en cuatro dimensiones: (i) cómo se producen las recomendaciones, (ii) cómo se presentan las recomendaciones a los usuarios, (iii) cómo se evalúan los sistemas de recomendación y (iv) cuáles son las limitaciones y oportunidades de investigación en el área.

Las evidencias se basan en estudios primarios publicados desde 2015 hasta 2020 provenientes de tres repositorios. A través de esta revisión, se proporciona una perspectiva global de la práctica basada en evidencias actual en ERS con el fin de apoyar a los profesionales e investigadores en la implementación y las futuras direcciones de investigación. Además, las limitaciones y oportunidades de investigación se resumen a la luz de los estudios actuales.

Los hallazgos, en términos de tendencias actuales, muestran que las técnicas híbridas son las más utilizadas en el campo de los sistemas de recomendación para el apoyo al enseñanza y aprendizaje. Además, se observa que se han priorizado enfoques que se ajustan naturalmente a un diseño centrado en el usuario (por ejemplo, técnicas que permiten representar las limitaciones educativas de los estudiantes) sobre aquellos basados en otros aspectos, como las características del ítem (por ejemplo, la técnica de Filtrado Basado en Contenido - CBF). Los resultados muestran que estos enfoques han sido reconocidos como los principales medios para apoyar a los usuarios con recomendaciones en su proceso de enseñanza y aprendizaje, y proporcionan direcciones para los profesionales e investigadores que buscan basar sus actividades e investigaciones en evidencias de estudios actuales. Por otro lado, este estudio también revela que técnicas altamente destacadas en el tema principal de los sistemas de recomendación en general, como los basados en bandit y los de aprendizaje profundo (Barraza-Urbina & Glowacka, 2020; Zhang et al., 2020), han sido poco explorados, lo que implica una discrepancia entre las áreas. Por lo tanto, el resultado de esta revisión sistemática indica que se debe emplear un mayor esfuerzo científico para investigar el potencial de estos enfoques no explorados.

Respecto a la presentación de recomendaciones, la visualización orgánica es la estrategia más utilizada. Sin embargo, la mayoría de las investigaciones tienden a no mostrar detalles del enfoque utilizado, lo que dificulta comprender el estado del arte de esta dimensión. Además, entre otros resultados, se observa que la mayoría de las evaluaciones de ERS se basan en la precisión de los recomendadores y en el análisis de la satisfacción del usuario. Este hallazgo abre oportunidades de investigación para el desarrollo de marcos de evaluación multidimensionales que apoyen eficazmente la verificación del impacto de las recomendaciones en el proceso de enseñanza y aprendizaje.

Por último, las limitaciones identificadas indican que las dificultades relacionadas con la obtención de datos para llevar a cabo evaluaciones de ERS son una realidad que se extiende por más de una década (Verbert et al., 2011) y requieren la atención de la comunidad científica para el tratamiento de esta situación. Asimismo, la falta de investigación profunda sobre el impacto de problemas conocidos en el campo de los sistemas de recomendación, otra limitación identificada, señala la importancia de aspectos que deben considerarse en el diseño y la evaluación de estos sistemas para proporcionar una mejor elucidación de su aplicación potencial en un escenario real.

En cuanto a las limitaciones y oportunidades de investigación, algunos de los hallazgos de este estudio indican la necesidad de un mayor esfuerzo en la realización de evaluaciones que proporcionen evidencia directa sobre la efectividad pedagógica de los sistemas y se sugiere el desarrollo de marcos de evaluación multidimensionales para ERS como una oportunidad de investigación. Además, se observó una escasez en el uso de conjuntos de datos públicos en los estudios actuales, lo que lleva a limitaciones en términos de reproducibilidad y comparación de recomendadores. Esto parece estar relacionado con un número limitado de conjuntos de datos públicos actualmente disponibles, y este aspecto también puede estar afectando el tamaño de los experimentos realizados por los investigadores.

En términos de las limitaciones de este estudio, la primera se refiere al número de fuentes de datos utilizadas para la selección de artículos. Solo se consideraron los repositorios mencionados en la Sección 3.1. Por lo tanto, el alcance de este trabajo se limita a evidencias de publicaciones indexadas por estas plataformas. Además, solo se examinaron publicaciones escritas en inglés, por lo tanto, los resultados de artículos escritos en otros idiomas están más allá del alcance de este trabajo. También, las limitaciones y oportunidades de investigación presentadas en la Sección 4.5 se identificaron en función de los datos extraídos utilizados para responder a las preguntas de investigación de esta SLR, por lo tanto, están limitadas a su alcance. Como consecuencia, no se identificaron ni se discutieron las limitaciones y oportunidades del campo de ERS que superan este contexto. Finalmente, la SLR se dirigió a artículos publicados en revistas científicas y, debido a esto, los resultados obtenidos no reflejan el estado del área desde la perspectiva de las publicaciones en conferencias. En futuras investigaciones, se pretende abordar tales limitaciones.
