{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendadores de TensorFlow para un sistema de recomendaciones potente\n",
    "- [Articulo](https://medium.com/@pauloyc/tensorflow-recommenders-for-powerful-recommendation-system-e3dec138a07f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo un sistema de recomendación de películas con Surprise y Python.\n",
    "- [Articulo](https://monirah-abdulaziz.medium.com/building-movie-recommendation-system-with-surprise-and-python-e905de755c61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_series_duration = merged_df_series.groupby(‘program_name’)[[‘duration_seconds’]].max()\n",
    "\n",
    "# # average_watching\n",
    "# merged_df_series[“average_watching”] = merged_df_series.apply(lambda x: 1 if x[‘duration_seconds’] > df_series_duration.loc[x.program_name,’duration_seconds’] else x[‘duration_seconds’]/df_series_duration.loc[x.program_name,’duration_seconds’], axis=1)\n",
    "# # total_duration \n",
    "# merged_df_series[“total_duration”]= merged_df_series.apply(lambda x: df_series_duration.loc[x.program_name,’duration_seconds’],axis=1)\n",
    "\n",
    "\n",
    "# # Extract minute by using (regex) and convert to appropriate type \n",
    "# merged_df_movie[‘total_duration’] = merged_df_movie[‘duration’].str.replace(r’min’, ‘’)\n",
    "# merged_df_movie[‘duration_seconds’] = pd.to_numeric((merged_df_movie[‘duration_seconds’]) , errors=’coerce’).astype(‘Int64’)\n",
    "# merged_df_movie[‘total_duration’] = pd.to_numeric((merged_df_movie[‘total_duration’]) , errors=’coerce’).astype(‘Int64’)\n",
    "\n",
    "# # convert from min to sec\n",
    "# merged_df_movie[‘total_duration’] = (merged_df_movie[‘total_duration’]*60)\n",
    "\n",
    "# merged_df_movie[“duration_seconds”] = merged_df_movie.apply(lambda x: x[‘total_duration’] if x[‘duration_seconds’] > x[‘total_duration’] else x[‘duration_seconds’], axis=1)\n",
    "\n",
    "# merged_df_movie[‘average_watching’]=merged_df_movie[‘duration_seconds’]/merged_df_movie[‘total_duration’]\n",
    "\n",
    "# reader = Reader(rating_scale=(0.03, 1.0))\n",
    "# data = Dataset.load_from_df(df_data[[‘user_id’, ‘show_id’, ‘average_watching’]], reader)\n",
    "# benchmark = []\n",
    "\n",
    "# # Iterate over all algorithms\n",
    "# for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(),\n",
    "#  KNNWithMeans(), KNNWithZScore(), BaselineOnly()]:\n",
    "#  # Perform cross validation\n",
    "#  results = cross_validate(algorithm, data, measures=[‘RMSE’], cv=3, verbose=False)\n",
    " \n",
    "#  # Get results & append algorithm name\n",
    "#  tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "#  tmp = tmp.append(pd.Series([str(algorithm).split(‘ ‘)[0].split(‘.’)[-1]], index=[‘Algorithm’]))\n",
    "#  benchmark.append(tmp)\n",
    "\n",
    "\n",
    "# print(‘Using ALS’)\n",
    "# bsl_options = {‘method’: ‘als’,\n",
    "#  “random_state”:250,\n",
    "#  ‘n_epochs’: 5,\n",
    "#  ‘reg_u’: 12,\n",
    "#  ‘reg_i’: 5\n",
    "#  }\n",
    "# algo = BaselineOnly(bsl_options)\n",
    "# cross_validate(algo, data, measures=[‘RMSE’], cv=3, verbose=False)\n",
    "\n",
    "\n",
    "# trainset, testset = train_test_split(data, test_size=0.25)\n",
    "# algo = BaselineOnly(bsl_options)\n",
    "# predictions = algo.fit(trainset).test(testset)\n",
    "# accuracy.rmse(predictions)\n",
    "\n",
    "\n",
    "# # user_id is the 13618\n",
    "# ratings = newdf.loc[newdf[‘user_id’] == 13618]\n",
    "# # obtain the required data of this user\n",
    "# ratings=ratings[[‘user_id’, ‘show_id’, ‘average_watching’]]\n",
    "# ratings\n",
    "\n",
    "# # user_id is the 13618\n",
    "# ratings = newdf.loc[newdf[‘user_id’] == 13618]\n",
    "# # obtain the required data of this user\n",
    "# ratings=ratings[[‘user_id’, ‘show_id’, ‘average_watching’]]\n",
    "# ratings\n",
    "\n",
    "# # get the list of the movie ids\n",
    "# unique_ids = newdf[‘show_id’].unique()\n",
    "# # get the list of the ids that the userid 13618 has watched\n",
    "# iids1001 = newdf.loc[newdf[‘user_id’]==13618, ‘show_id’]\n",
    "# # remove the rated movies for the recommendations\n",
    "# movies_to_predict = np.setdiff1d(unique_ids,iids1001)\n",
    "\n",
    "# algo = BaselineOnly(bsl_options)\n",
    "# algo.fit(data.build_full_trainset())\n",
    "# my_recs = []\n",
    "# for iid in movies_to_predict:\n",
    "#  my_recs.append((iid, algo.predict(uid=’13618',iid=iid).est))\n",
    "# pd.DataFrame(my_recs, columns=[‘iid’, ‘predictions’]).sort_values(‘predictions’, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sistema-de-recomendacion-unab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
