# def calculate_score_dataset(df: pd.DataFrame, features: Dict[str, Tuple[float, float]], weights: Dict[str, float], new_column: str) -> pd.DataFrame:
#     """
#     Calcula un score normalizado para cada fila del DataFrame, basado en las características y sus pesos.

#     Parameters:
#     - df (pd.DataFrame): El DataFrame con las características de los ítems.
#     - features (Dict[str, Tuple[float, float]]): Diccionario con las características y sus rangos min, max en el formato {"característica": (min, max)}.
#     - weights (Dict[str, float]): Diccionario con los pesos asignados a cada característica, los cuales deben sumar 1.
#     - new_column (str): Nombre de la columna nueva donde se guardarán los scores calculados.

#     Returns:
#     - pd.DataFrame: El DataFrame con la nueva columna 'score'.
#     """
#     # Función para calcular el score normalizado para cada fila
#     def calculate_score_row(values: Dict[str, float]) -> float:
#         score = 0
#         for feature, (min_val, max_val) in features.items():
#             if feature in values:
#                 # Normaliza el valor de la característica
#                 normalized_value = (values[feature] - min_val) / (max_val - min_val) if max_val != min_val else 0
#                 # Suma la contribución ponderada al score
#                 score += weights.get(feature, 0) * normalized_value
#         return score
    
#     # Aplicar el cálculo de score a cada fila del DataFrame
#     df[new_column] = df.apply(
#         lambda row: calculate_score_row({feature: row[feature] for feature in features}),
#         axis=1
#     )
    
#     return df













https://medium.com/@lifengyi_6964/multimodal-and-large-language-model-recommendation-system-awesome-paper-list-a05e5fd81a79

# Recommender Systems in the Era of Large Language Models  

- [Articulo](https://arxiv.org/pdf/2307.02046)
- [Publicacion](https://www.linkedin.com/pulse/trends-recsys-two-towers-llms-vijay-raghavan-ph-d-m-b-a-/)


# Scaling deep retrieval with TensorFlow Recommenders and Vertex AI Matching Engine
- [ENLACE](https://cloud.google.com/blog/products/ai-machine-learning/scaling-deep-retrieval-tensorflow-two-towers-architecture)
- https://developers.google.com/machine-learning/recommendation/overview/candidate-generation?hl=es-419#embedding-space

# Introducing TensorFlow Recommenders

- [Artiuclo](https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html?hl=es-419&_gl=1*1874wvg*_ga*NzE5MDE3NjczLjE3MTI5NDc0Mjk.*_ga_W0YLR4190T*MTcxODMzMjAzOS4xOS4xLjE3MTgzMzIyMzIuMC4wLjA.)



https://medium.com/@eng.saavedra/sistemas-de-recomendaci%C3%B3n-parte-5-modelos-complejos-c8db70e8b7b

RecSysUnab.py --exers [0,1,0,0,0,1....50] --id n 

https://medium.com/@eng.saavedra/sistemas-de-recomendaci%C3%B3n-parte-5-modelos-complejos-c8db70e8b7b
https://towardsdatascience.com/two-tower-networks-and-negative-sampling-in-recommender-systems-fdc88411601b

# SURPRISE
https://monirah-abdulaziz.medium.com/building-movie-recommendation-system-with-surprise-and-python-e905de755c61

# MATRIX factorization
https://medium.com/@chenycy/build-recommendation-systems-openais-embeddings-matrix-factorization-and-deep-learning-0cac62008f0c

https://actsusanli.medium.com/building-a-recommender-system-with-implicit-feedback-datasets-using-alternating-least-squares-64d4f5ba3c57


https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Building%20Recommender%20System%20with%20Surprise.ipynb
https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b
https://nbviewer.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb


https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Collaborative%20Filtering%20Model%20with%20TensorFlow.ipynb
https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-tensorflow-82e63d27b420


https://arxiv.org/abs/cs/0702144


https://medium.com/@eng.saavedra/sistemas-de-recomendaci%C3%B3n-parte-4-evaluaciones-cfd1f96b887a


model_combined_score_3 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(x_train_combined_score_3.shape[1],)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='linear')
])

model_combined_score_3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')
model_combined_score_3.summary()

history_combined_score_3 = model_combined_score_3.fit(x_train_combined_score_3, y_train_combined_score_3, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

print()
loss_combined_score_3 = model_combined_score_3.evaluate(x_test_combined_score_3, y_test_combined_score_3)
print(f'Loss en el conjunto de prueba: {loss_combined_score_3}')
predictions_combined_score_3 = model_combined_score_3.predict(x_test_combined_score_3)









from sklearn.metrics import precision_score, recall_score

# Supongamos que tienes las siguientes listas:
# etiquetas_reales: una lista que indica qué ítems son relevantes (1 si es relevante, 0 si no).
# recomendaciones: una lista que contiene las recomendaciones del modelo (1 si el ítem fue recomendado, 0 si no).

# Ejemplo de etiquetas reales y recomendaciones
# Esto debería ser un resultado de tu evaluación del modelo
# Simulación de etiquetas reales para un conjunto de usuarios
etiquetas_reales = np.array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])  # Etiquetas de relevancia
recomendaciones = np.array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1])  # Recomendaciones del modelo

# Calcular precisión y recall
precision = precision_score(etiquetas_reales, recomendaciones)
recall = recall_score(etiquetas_reales, recomendaciones)

print(f"Precisión: {precision:.4f}")
print(f"Recall: {recall:.4f}")


















import tensorflow as tf
from tensorflow.keras.layers import Embedding, Dense, Flatten, Input, Concatenate, Dot
from tensorflow.keras.models import Model

# Supongamos que tenemos los siguientes datos
num_users = 100  # Número de usuarios
num_exercises = 50  # Número de ejercicios
embedding_dim = 16  # Dimensión de los embeddings

# Torre de Usuario
user_career_input = Input(shape=(1,), name="user_career")  # Carrera
user_exercises_input = Input(shape=(num_exercises,), name="user_exercises")  # Ejercicios completados (binario)
user_scores_input = Input(shape=(3,), name="user_scores")  # Puntajes A, B y C

# Embedding de carrera
user_career_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim)(user_career_input)
user_career_embedding = Flatten()(user_career_embedding)

# Concatenamos todas las características del usuario
user_features = Concatenate()([user_career_embedding, user_exercises_input, user_scores_input])

# Pasamos las características de usuario por una capa densa
user_dense = Dense(embedding_dim, activation="relu")(user_features)

# Torre de Ejercicio
exercise_hito_input = Input(shape=(1,), name="exercise_hito")  # Hito
exercise_knowledge_input = Input(shape=(1,), name="exercise_knowledge")  # Conocimiento
exercise_skill_input = Input(shape=(1,), name="exercise_skill")  # Habilidad

# Embeddings de hito, conocimiento y habilidad
exercise_hito_embedding = Embedding(input_dim=10, output_dim=embedding_dim)(exercise_hito_input)
exercise_knowledge_embedding = Embedding(input_dim=10, output_dim=embedding_dim)(exercise_knowledge_input)
exercise_skill_embedding = Embedding(input_dim=10, output_dim=embedding_dim)(exercise_skill_input)

# Aplanamos y concatenamos todas las características de ejercicio
exercise_features = Concatenate()([
    Flatten()(exercise_hito_embedding),
    Flatten()(exercise_knowledge_embedding),
    Flatten()(exercise_skill_embedding)
])

# Pasamos las características del ejercicio por una capa densa
exercise_dense = Dense(embedding_dim, activation="relu")(exercise_features)

# Cálculo de similitud entre usuario y ejercicio (producto punto)
similarity = Dot(axes=1)([user_dense, exercise_dense])

# Modelo de recomendación completo
model = Model(inputs=[
    user_career_input, user_exercises_input, user_scores_input,
    exercise_hito_input, exercise_knowledge_input, exercise_skill_input
], outputs=similarity)

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Resumen del modelo
model.summary()


# Ejemplo de datos de entrenamiento
import numpy as np

# IDs ficticios para entrenamiento
user_careers = np.random.randint(0, num_users, size=1000)
user_exercises = np.random.randint(0, 2, size=(1000, num_exercises))  # Lista binaria de ejercicios hechos
user_scores = np.random.randint(0, 10, size=(1000, 3))  # Puntajes A, B y C
exercise_hitos = np.random.randint(0, 10, size=1000)
exercise_knowledge = np.random.randint(0, 10, size=1000)
exercise_skill = np.random.randint(0, 10, size=1000)
labels = np.random.randint(0, 2, size=1000)  # 1 si el usuario hizo el ejercicio, 0 si no

# Entrenar el modelo
model.fit(
    [user_careers, user_exercises, user_scores, exercise_hitos, exercise_knowledge, exercise_skill],
    labels,
    epochs=10,
    batch_size=32
)

# Datos del usuario
user_career = np.array([2])  # ID de la carrera del usuario
user_exercises = np.array([[1, 0, 1, 0, ..., 1]])  # Lista binaria de ejercicios realizados (asegúrate que sea del tamaño correcto)
user_scores = np.array([[5, 7, 3]])  # Puntajes A, B y C del usuario

# Datos del ejercicio
exercise_hito = np.array([3])  # Hito del ejercicio
exercise_knowledge = np.array([2])  # Conocimiento requerido
exercise_skill = np.array([4])  # Habilidad requerida

# Hacer la predicción de afinidad
prediction = model.predict([user_career, user_exercises, user_scores, exercise_hito, exercise_knowledge, exercise_skill])

print("Afinidad usuario-ejercicio:", prediction[0][0])





from sklearn.metrics.pairwise import cosine_similarity

# Ejemplo de perfil de un nuevo usuario
new_user_profile = np.array([[2, 5, 7, 3]])  # [carrera, puntaje A, puntaje B, puntaje C]

# Perfiles de ejercicios (matriz de n_ejercicios x características)
exercise_profiles = np.array([
    [3, 4, 6, 2],  # Ejercicio 1
    [2, 5, 7, 3],  # Ejercicio 2, etc.
    ...
])

# Calcular la similitud entre el nuevo usuario y todos los ejercicios
similarity_scores = cosine_similarity(new_user_profile, exercise_profiles)
recommended_exercise_indices = similarity_scores.argsort()[0][-5:]  # Índices de los 5 ejercicios más similares


# Ejemplo de lista de ejercicios y su popularidad
exercises_popularity = {
    "Ejercicio A": 150,
    "Ejercicio B": 125,
    "Ejercicio C": 100,
    ...
}

# Ordenar ejercicios por popularidad y seleccionar los más altos
popular_exercises = sorted(exercises_popularity, key=exercises_popularity.get, reverse=True)[:5]
print("Recomendación de ejercicios populares:", popular_exercises)



# Supongamos que `content_based_recommendations` es la lista obtenida de la estrategia 2
# Y `popular_exercises` es la lista de la estrategia 3

def hybrid_recommendation(user_profile, top_n=5):
    if is_new_user(user_profile):
        # Para nuevos usuarios, mezclamos basados en contenido y popularidad
        recommendations = popular_exercises[:top_n] + content_based_recommendations[:top_n]
    else:
        # Para usuarios con historial, usamos el modelo de dos torres
        recommendations = model.predict(user_profile)[:top_n]
    
    return recommendations[:top_n]

# Ejemplo de uso
recommendations = hybrid_recommendation(new_user_profile)
print("Recomendaciones híbridas:", recommendations)




import numpy as np
import tensorflow as tf
from keras.layers import Embedding, Dense, Flatten
from keras.models import Model
from keras.layers import Input, Concatenate

# Datos simulados
num_users = 1000    # Número de usuarios
num_movies = 500    # Número de películas
embedding_dim = 32  # Dimensión de los embeddings

# Datos de usuario y película
user_ids = np.random.randint(0, num_users, size=10000)
movie_ids = np.random.randint(0, num_movies, size=10000)
labels = np.random.randint(0, 2, size=10000)  # 1 si le gustó, 0 si no


# Datos simulados
num_users = 1000    # Número de usuarios
num_movies = 500    # Número de películas
embedding_dim = 32  # Dimensión de los embeddings

# Datos de usuario y película
user_ids = np.random.randint(0, num_users, size=10000)
movie_ids = np.random.randint(0, num_movies, size=10000)
labels = np.random.randint(0, 2, size=10000)  # 1 si le gustó, 0 si no

labels

# Torre para usuarios
user_input = Input(shape=(1,), name="user_id")
user_embedding = Embedding(input_dim=num_users, output_dim=embedding_dim, name="user_embedding")(user_input)
user_embedding = Flatten()(user_embedding)

# Torre para películas
movie_input = Input(shape=(1,), name="movie_id")
movie_embedding = Embedding(input_dim=num_movies, output_dim=embedding_dim, name="movie_embedding")(movie_input)
movie_embedding = Flatten()(movie_embedding)

# Similaridad entre usuario y película (producto punto)
dot_product = tf.keras.layers.Dot(axes=1)([user_embedding, movie_embedding])

# Modelo completo
model = Model(inputs=[user_input, movie_input], outputs=dot_product)
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Entrenamiento del modelo
model.fit([user_ids, movie_ids], labels, epochs=10, batch_size=64)

# Predicción de la preferencia de un usuario para una película específica
user_id = np.array([4])  # ID del usuario
movie_id = np.array([10])  # ID de la película

predicted_preference = model.predict([user_id, movie_id])
print(f"Predicción de que al usuario {user_id[0]} le gustará la película {movie_id[0]}: {predicted_preference[0][0]}")






model_combined_score_1 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(x_train_combined_score_1.shape[1],)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='linear')
])

model_combined_score_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')
model_combined_score_1.summary()

history_combined_score_1 = model_combined_score_1.fit(x_train_combined_score_1, y_train_combined_score_1, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

print()
loss_combined_score_1 = model_combined_score_1.evaluate(x_test_combined_score_1, y_test_combined_score_1)
print(f'Loss en el conjunto de prueba: {loss_combined_score_1}')
predictions_combined_score_1 = model_combined_score_1.predict(x_test_combined_score_1)

































# # Crear el modelo
# model = TwoTowerModel(user_feature_size, item_feature_size, embedding_size)

# # Definir el optimizador y la función de pérdida
# optimizer = optim.Adam(model.parameters(), lr=0.001)
# criterion = nn.BCELoss()

# # Extraer las características de los DataFrames y convertirlas en tensores
# item_input = torch.tensor(df_items.iloc[:, 1:].values).float()  # Datos de ejercicios
# user_input = torch.tensor(df_users.iloc[:, 1:].values).float()  # Datos de usuarios

# # Etiquetas simuladas (si el ejercicio debe recomendarse o no)
# labels = torch.randint(0, 2, (len(df_users),)).float()

# # Entrenar el modelo
# epochs = 10
# for epoch in range(epochs):
#     optimizer.zero_grad()
    
#     # Pasar las entradas a través del modelo
#     output = model(user_input, item_input)
    
#     # Calcular la pérdida
#     loss = criterion(output, labels)
    
#     # Retropropagación
#     loss.backward()
    
#     # Actualizar los pesos
#     optimizer.step()
    
#     print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")



# def recommend_for_user(model, user_features, item_features, top_n=10):
#     """
#     Recomendaciones para un solo usuario basado en sus características.

#     Args:
#         model: El modelo de recomendación preentrenado.
#         user_features: Un array con las características del usuario.
#         item_features: Un tensor con las características de todos los ítems.
#         top_n: Número de recomendaciones a devolver.

#     Returns:
#         recomendaciones: Índices de los ítems recomendados.
#         scores: Puntuaciones de recomendación.
#     """
#     # Asegurarse de que las características del usuario son un tensor y de la forma correcta
#     user_input = torch.tensor(user_features).float().unsqueeze(0)  # Añadir una dimensión para el batch
    
#     # Expandir las características del ítem para tener las combinaciones usuario-ítem
#     num_items = item_features.size(0)
#     item_input_expanded = item_features.repeat(user_input.size(0), 1)  # Repetir las características de los ítems para el usuario
    
#     # Poner el modelo en modo de evaluación
#     model.eval()
    
#     # Obtener las puntuaciones de todos los ítems
#     with torch.no_grad():
#         item_scores = model(user_input, item_input_expanded)
    
#     # Obtener los índices de los top_n ítems
#     top_indices = torch.topk(item_scores, top_n).indices.squeeze().tolist()
#     scores = item_scores[top_indices].tolist()
    
#     return top_indices, scores

































# import tensorflow as tf
# import tensorflow_recommenders as tfrs
# import pandas as pd

# # Supongamos que el DataFrame tiene las siguientes columnas: 'id_user', 'id_item', 'title_item', 'ranking_item'
# data = pd.DataFrame({
#     "id_user": ["user1", "user2", "user3", "user42"],
#     "id_item": ["item1", "item2", "item3", "item42"],
#     "title_item": ["Movie A", "Movie B", "Movie C", "Movie D"],
#     "ranking_item": [5, 3, 4, 2]
# })

# # Convertimos el DataFrame a un tf.data.Dataset
# ratings = tf.data.Dataset.from_tensor_slices({
#     "title_item": data["title_item"].values,
#     "id_user": data["id_user"].values,
# })

# # Configuramos el modelo Two Tower
# class TwoTowerRecommendationModel(tfrs.Model):
#     def __init__(self):
#         super().__init__()
#         embedding_dim = 32

#         # Modelo para el usuario
#         self.user_model = tf.keras.Sequential([
#             tf.keras.layers.experimental.preprocessing.StringLookup(
#                 max_tokens=data["id_user"].nunique()),
#             tf.keras.layers.Embedding(data["id_user"].nunique() + 1, embedding_dim)
#         ])

#         # Modelo para el ítem
#         self.item_model = tf.keras.Sequential([
#             tf.keras.layers.experimental.preprocessing.StringLookup(
#                 max_tokens=data["title_item"].nunique()),
#             tf.keras.layers.Embedding(data["title_item"].nunique() + 1, embedding_dim)
#         ])

#         # Definimos la tarea de recuperación con métricas de top-k
#         self.task = tfrs.tasks.Retrieval(
#             metrics=tfrs.metrics.FactorizedTopK(
#                 candidates=ratings.batch(128).map(self.item_model)
#             )
#         )

#     def compute_loss(self, features, training=False):
#         user_embeddings = self.user_model(features["id_user"])
#         item_embeddings = self.item_model(features["title_item"])
#         return self.task(user_embeddings, item_embeddings)

# # Entrenamiento del modelo
# model = TwoTowerRecommendationModel()
# model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))
# model.fit(ratings.batch(128), epochs=5, verbose=1)

# # Indexación para recomendaciones
# index = tfrs.layers.ann.BruteForce(model.user_model)
# index.index(ratings.batch(128).map(model.item_model), ratings)

# # Obtener recomendaciones para un usuario específico
# _, recommended_titles = index(tf.constant(["user42"]))
# print(f"Recommendations for user 'user42': {recommended_titles[0, :3]}")