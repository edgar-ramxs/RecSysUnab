# # Definimos la torre para los usuarios
# class UserTower(nn.Module):
#     def __init__(self, user_input_size, embedding_size):
#         super(UserTower, self).__init__()
#         self.fc = nn.Sequential(
#             nn.Linear(user_input_size, 128),
#             nn.ReLU(),
#             nn.Linear(128, embedding_size)
#         )
    
#     def forward(self, x):
#         return self.fc(x)

# # Definimos la torre para los ejercicios
# class ItemTower(nn.Module):
#     def __init__(self, item_input_size, embedding_size):
#         super(ItemTower, self).__init__()
#         self.fc = nn.Sequential(
#             nn.Linear(item_input_size, 128),
#             nn.ReLU(),
#             nn.Linear(128, embedding_size)
#         )
    
#     def forward(self, x):
#         return self.fc(x)

# # Definimos el modelo de dos torres
# class TwoTowerModel(nn.Module):
#     def __init__(self, user_input_size, item_input_size, embedding_size):
#         super(TwoTowerModel, self).__init__()
#         self.user_tower = UserTower(user_input_size, embedding_size)
#         self.item_tower = ItemTower(item_input_size, embedding_size)
    
#     def forward(self, user_input, item_input):
#         # Obtener los embeddings para usuarios y ejercicios
#         user_embedding = self.user_tower(user_input)
#         item_embedding = self.item_tower(item_input)
        
#         # Calcular la similitud como el producto punto entre los embeddings
#         score = torch.sum(user_embedding * item_embedding, dim=1)
        
#         return torch.sigmoid(score)



# # Crear el modelo
# model = TwoTowerModel(user_feature_size, item_feature_size, embedding_size)

# # Definir el optimizador y la función de pérdida
# optimizer = optim.Adam(model.parameters(), lr=0.001)
# criterion = nn.BCELoss()

# # Extraer las características de los DataFrames y convertirlas en tensores
# item_input = torch.tensor(df_items.iloc[:, 1:].values).float()  # Datos de ejercicios
# user_input = torch.tensor(df_users.iloc[:, 1:].values).float()  # Datos de usuarios

# # Crear pares de usuario e ítem
# num_users = len(df_users)
# num_items = len(df_items)

# # Expandir las características para crear combinaciones de usuarios e ítems
# user_input_expanded = user_input.unsqueeze(1).expand(-1, num_items, -1).reshape(-1, user_feature_size)  # Replicamos las características del usuario
# item_input_expanded = item_input.repeat(num_users, 1)  # Repetimos las características de los ítems

# # Asegurarse de que las dimensiones son correctas
# print(f"User input expanded shape: {user_input_expanded.shape}")
# print(f"Item input expanded shape: {item_input_expanded.shape}")


# # Entrenar el modelo
# epochs = 30
# for epoch in range(epochs):
#     optimizer.zero_grad()
    
#     # Pasar las entradas a través del modelo
#     output = model(user_input_expanded, item_input_expanded)
    
#     # Calcular la pérdida (debes crear etiquetas correspondientes a los pares)
#     labels = torch.randint(0, 2, (len(output),)).float()  # Ajustar el tamaño de las etiquetas
#     loss = criterion(output, labels)
    
#     # Retropropagación
#     loss.backward()
    
#     # Actualizar los pesos
#     optimizer.step()
    
#     print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")


# # Prueba: Predecir la probabilidad de recomendar un ejercicio a un usuario
# with torch.no_grad():
#     predictions = model(user_input_expanded, item_input_expanded)
#     print("Predicciones:", predictions)



# # Ejemplo de uso
# user_id_to_recommend = 0  # Cambia esto al ID del usuario que deseas recomendar
# print(f'Ejercicios Relizados por el estudiante: {user_id_to_recommend}')
# print([idx[1:] if idx.startswith('e') else idx for idx in mf_dataset[mf_dataset['id_estudiante'] == user_id_to_recommend].iloc[:, 1:].columns[mf_dataset[mf_dataset['id_estudiante'] == user_id_to_recommend].iloc[:, 1:].values[0] == 1].tolist()])



# reco = recomendacion_ejercicios(predictions, user_id_to_recommend, catalogo, mf_dataset)
# print(f"Recomendaciones para el usuario {user_id_to_recommend}:")
# reco.head(15)











































# DNC




# # Remapear los valores de id_estudiante e id_ejercicio a índices consecutivos
# df_interactions['user_index'] = pd.factorize(df_interactions['id_estudiante'])[0]
# df_interactions['item_index'] = pd.factorize(df_interactions['id_ejercicio'])[0]


# # Obtener los valores únicos de id_estudiante e id_ejercicio
# num_users = df_interactions['user_index'].nunique()     # Número único de usuarios
# num_items = df_interactions['item_index'].nunique()     # Número único de ítems

# # Convertir los datos a tensores de PyTorch
# user_ids = torch.tensor(df_interactions['user_index'].values).long()    # Convertir a tipo long (índices enteros)
# item_ids = torch.tensor(df_interactions['item_index'].values).long()    # Convertir a tipo long (índices enteros)
# labels = torch.tensor(df_interactions['score'].values).float()          # Convertir a tipo float para las etiquetas

# # Modelo de recomendación
# class RecommenderNet(nn.Module):
#     def __init__(self, num_users, num_items, embedding_size=10):
#         super(RecommenderNet, self).__init__()
#         self.user_embedding = nn.Embedding(num_users, embedding_size)
#         self.item_embedding = nn.Embedding(num_items, embedding_size)

#     def forward(self, user_ids, item_ids):
#         user_vecs = self.user_embedding(user_ids)
#         item_vecs = self.item_embedding(item_ids)
#         dot_product = (user_vecs * item_vecs).sum(dim=1)
#         return dot_product

# # Inicializar el modelo
# embedding_size = 10
# model = RecommenderNet(num_users, num_items, embedding_size)
# loss_fn = nn.MSELoss()
# optimizer = optim.Adam(model.parameters(), lr=0.01)

# # Entrenamiento
# for epoch in range(100):
#     model.train()
#     optimizer.zero_grad()
#     preds = model(user_ids, item_ids)
#     loss = loss_fn(preds, labels)
#     loss.backward()
#     optimizer.step()

#     if epoch % 10 == 0:
#         print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# # Para hacer recomendaciones a usuarios que no tienen interacciones:
# def recommend_for_user(user_id, num_recommendations=5):
#     # Crear un tensor con los item_ids para hacer las predicciones
#     all_item_ids = torch.tensor(range(num_items))  # Esto asume que los items van de 0 a num_items-1

#     # Hacer las predicciones para todos los items posibles para este usuario
#     model.eval()
#     user_tensor = torch.tensor([user_id] * num_items)  # Replicar el user_id para todos los items
#     with torch.no_grad():
#         preds = model(user_tensor, all_item_ids).cpu().numpy()

#     # Ordenar los items por las predicciones más altas
#     recommended_item_ids = preds.argsort()[-num_recommendations:][::-1]  # Top N items recomendados
#     return recommended_item_ids


# # Ejemplo: recomendar 5 ítems para un usuario específico
# user_id_to_recommend = 0  # El ID del usuario para el cual hacer recomendaciones
# recommended_items = recommend_for_user(user_id_to_recommend, num_recommendations=10)
# print(f"Recomendaciones para el usuario {user_id_to_recommend}: {recommended_items}")


























# import torch
# import torch.nn as nn
# import torch.optim as optim

# class RecommenderSystemDCN:
#     def __init__(self, df_interactions, embedding_size=10, learning_rate=0.01):
#         # Remapeo de ID de estudiantes e ID de ejercicios a índices consecutivos
#         df_interactions['user_index'] = pd.factorize(df_interactions['id_estudiante'])[0]
#         df_interactions['item_index'] = pd.factorize(df_interactions['id_ejercicio'])[0]
        
#         # Guardar el número único de usuarios y de ítems
#         self.num_users = df_interactions['user_index'].nunique()
#         self.num_items = df_interactions['item_index'].nunique()
        
#         # Convertir los datos a tensores de PyTorch
#         self.user_ids = torch.tensor(df_interactions['user_index'].values).long()
#         self.item_ids = torch.tensor(df_interactions['item_index'].values).long()
#         self.labels = torch.tensor(df_interactions['score'].values).float()
        
#         # Definir y inicializar el modelo de recomendación
#         self.model = self.RecommenderNet(self.num_users, self.num_items, embedding_size)
#         self.loss_fn = nn.MSELoss()
#         self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)

#     class RecommenderNet(nn.Module):
#         def __init__(self, num_users, num_items, embedding_size):
#             super().__init__()
#             self.user_embedding = nn.Embedding(num_users, embedding_size)
#             self.item_embedding = nn.Embedding(num_items, embedding_size)

#         def forward(self, user_ids, item_ids):
#             user_vecs = self.user_embedding(user_ids)
#             item_vecs = self.item_embedding(item_ids)
#             dot_product = (user_vecs * item_vecs).sum(dim=1)
#             return dot_product

#     def train(self, epochs=100, print_every=10):
#         for epoch in range(epochs):
#             self.model.train()
#             self.optimizer.zero_grad()
#             preds = self.model(self.user_ids, self.item_ids)
#             loss = self.loss_fn(preds, self.labels)
#             loss.backward()
#             self.optimizer.step()
            
#             if epoch % print_every == 0:
#                 print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

#     def recommend_for_user(self, user_id, num_recommendations=5):
#         # Crear tensor con todos los posibles item_ids
#         all_item_ids = torch.tensor(range(self.num_items)).long()
#         user_tensor = torch.tensor([user_id] * self.num_items).long()
        
#         # Predecir scores para todos los ítems y ordenar para recomendar
#         self.model.eval()
#         with torch.no_grad():
#             preds = self.model(user_tensor, all_item_ids).cpu().numpy()
        
#         recommended_item_ids = preds.argsort()[-num_recommendations:][::-1]
#         return recommended_item_ids

















# class RecommenderSystemDCN:
#     def __init__(self, df_interactions, embedding_size=10, learning_rate=0.01):
#         # Remapeo de ID de estudiantes e ID de ejercicios a índices consecutivos
#         df_interactions['user_index'] = factorize(df_interactions['id_estudiante'])[0]
#         df_interactions['item_index'] = factorize(df_interactions['id_ejercicio'])[0]
        
#         # Guardar el número único de usuarios y de ítems
#         self.num_users = df_interactions['user_index'].nunique()
#         self.num_items = df_interactions['item_index'].nunique()
        
#         # Convertir los datos a tensores de PyTorch
#         self.user_ids = torch.tensor(df_interactions['user_index'].values).long()
#         self.item_ids = torch.tensor(df_interactions['item_index'].values).long()
#         self.labels = torch.tensor(df_interactions['score'].values).float()
        
#         # Definir y inicializar el modelo de recomendación
#         self.model = self.RecommenderNet(self.num_users, self.num_items, embedding_size)
#         self.loss_fn = nn.MSELoss()
#         self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)

#     class RecommenderNet(nn.Module):
#         def __init__(self, num_users, num_items, embedding_size):
#             super().__init__()
#             self.user_embedding = nn.Embedding(num_users, embedding_size)
#             self.item_embedding = nn.Embedding(num_items, embedding_size)

#         def forward(self, user_ids, item_ids):
#             user_vecs = self.user_embedding(user_ids)
#             item_vecs = self.item_embedding(item_ids)
#             dot_product = (user_vecs * item_vecs).sum(dim=1)
#             return dot_product

#     def train(self, epochs=100, print_every=10):
#         for epoch in range(epochs):
#             self.model.train()
#             self.optimizer.zero_grad()
#             preds = self.model(self.user_ids, self.item_ids)
#             loss = self.loss_fn(preds, self.labels)
#             loss.backward()
#             self.optimizer.step()
            
#             if epoch % print_every == 0:
#                 print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

#     def recommend_for_user(self, user_id, num_recommendations=5):
#         all_item_ids = torch.tensor(range(self.num_items)).long()
#         user_tensor = torch.tensor([user_id] * self.num_items).long()
        
#         self.model.eval()
#         with torch.no_grad():
#             preds = self.model(user_tensor, all_item_ids).cpu().numpy()
        
#         recommended_item_ids = preds.argsort()[-num_recommendations:][::-1]
#         return recommended_item_ids

#     def save_model(self, file_path):
#         # Guardar el modelo y los parámetros del optimizador en un archivo
#         torch.save({
#             'model_state_dict': self.model.state_dict(),
#             'optimizer_state_dict': self.optimizer.state_dict()
#         }, file_path)
#         print(f"Modelo guardado en {file_path}")

#     def load_model(self, file_path):
#         # Cargar el modelo y los parámetros del optimizador desde un archivo
#         checkpoint = torch.load(file_path)
#         self.model.load_state_dict(checkpoint['model_state_dict'])
#         self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
#         print(f"Modelo cargado desde {file_path}")





















